nohup: ignoring input
Finish loading stage 0 dataset!
Train size: 97
Val size: 20
Test size: 20
Start target matching of Stage 1. This may take several minutes.
[nltk_data] Downloading package punkt to
[nltk_data]     /home/is/kaifan-l/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to
[nltk_data]     /home/is/kaifan-l/nltk_data...
[nltk_data]   Package punkt is already up-to-date!

0it [00:00, ?it/s]
637it [00:00, 732594.36it/s]

0it [00:00, ?it/s]
122it [00:00, 559852.39it/s]

0it [00:00, ?it/s]
139it [00:00, 562206.61it/s]mkdir: cannot create directory ‘./output/AMI/stage_1/trainer_output’: File exists
2024-02-19 15:44:46 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='./output/AMI/stage_1/trainer_output/bin/', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='source', srcdict='dict.txt', target_lang='target', task='translation', tensorboard_logdir=None, testpref=None, tgtdict='dict.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='./output/AMI/stage_1/trainer_output/train.bpe', user_dir=None, validpref='./output/AMI/stage_1/trainer_output/val.bpe', workers=60)
2024-02-19 15:44:47 | INFO | fairseq_cli.preprocess | [source] Dictionary: 50264 types
2024-02-19 15:44:48 | INFO | fairseq_cli.preprocess | [source] ./output/AMI/stage_1/trainer_output/train.bpe.source: 637 sents, 592982 tokens, 0.0% replaced by <unk>
2024-02-19 15:44:48 | INFO | fairseq_cli.preprocess | [source] Dictionary: 50264 types
2024-02-19 15:44:50 | INFO | fairseq_cli.preprocess | [source] ./output/AMI/stage_1/trainer_output/val.bpe.source: 122 sents, 113716 tokens, 0.0% replaced by <unk>
2024-02-19 15:44:50 | INFO | fairseq_cli.preprocess | [target] Dictionary: 50264 types
2024-02-19 15:44:52 | INFO | fairseq_cli.preprocess | [target] ./output/AMI/stage_1/trainer_output/train.bpe.target: 637 sents, 138962 tokens, 0.0% replaced by <unk>
2024-02-19 15:44:52 | INFO | fairseq_cli.preprocess | [target] Dictionary: 50264 types
2024-02-19 15:44:53 | INFO | fairseq_cli.preprocess | [target] ./output/AMI/stage_1/trainer_output/val.bpe.target: 122 sents, 31493 tokens, 0.0% replaced by <unk>
2024-02-19 15:44:53 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to ./output/AMI/stage_1/trainer_output/bin/

CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.
To initialize your shell, run

    $ conda init <SHELL_NAME>

Currently supported shells are:
  - bash
  - fish
  - tcsh
  - xonsh
  - zsh
  - powershell

See 'conda init --help' for more information and options.

IMPORTANT: You may need to close and restart your shell after running 'conda init'.


2024-02-19 15:44:56 | INFO | fairseq_cli.train | Namespace(activation_fn='gelu', adam_betas='(0.9, 0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='bart_large', attention_dropout=0.1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.1, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='./output/AMI/stage_1/trainer_output/bin/', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_layerdrop=0, decoder_layers=12, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=False, decoder_output_dim=1024, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=12, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=False, end_learning_rate=0.0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=True, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[3e-05], lr_scheduler='polynomial_decay', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=2048, max_tokens_valid=2048, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=2, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=1, required_seq_len_multiple=1, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, restore_file='./bart.large.cnn/model.pt', save_dir='./output/AMI/stage_1/trainer_output/checkpoints', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=True, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='source', stop_time_hours=0, target_lang='target', task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, total_num_update=30000, tpu=False, train_subset='train', truncate_source=True, update_freq=[4], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=500, weight_decay=0.01, zero_sharding='none')
2024-02-19 15:44:56 | INFO | fairseq.tasks.translation | [source] dictionary: 50264 types
2024-02-19 15:44:56 | INFO | fairseq.tasks.translation | [target] dictionary: 50264 types
2024-02-19 15:44:56 | INFO | fairseq.data.data_utils | loaded 122 examples from: ./output/AMI/stage_1/trainer_output/bin/valid.source-target.source
2024-02-19 15:44:56 | INFO | fairseq.data.data_utils | loaded 122 examples from: ./output/AMI/stage_1/trainer_output/bin/valid.source-target.target
2024-02-19 15:44:56 | INFO | fairseq.tasks.translation | ./output/AMI/stage_1/trainer_output/bin/ valid source-target 122 examples
2024-02-19 15:45:13 | INFO | fairseq_cli.train | BARTModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50264, 1024, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)
    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (6): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (7): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (8): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (9): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (10): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (11): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50264, 1024, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)
    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (6): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (7): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (8): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (9): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (10): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (11): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=1024, out_features=50264, bias=False)
  )
  (classification_heads): ModuleDict()
)
2024-02-19 15:45:13 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2024-02-19 15:45:13 | INFO | fairseq_cli.train | model: bart_large (BARTModel)
2024-02-19 15:45:13 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2024-02-19 15:45:13 | INFO | fairseq_cli.train | num. model params: 406290432 (num. trained: 406290432)
2024-02-19 15:45:14 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2024-02-19 15:45:14 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2024-02-19 15:45:14 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-02-19 15:45:14 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 23.870 GB ; name = Quadro P6000                            
2024-02-19 15:45:14 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-02-19 15:45:14 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2024-02-19 15:45:14 | INFO | fairseq_cli.train | max tokens per GPU = 2048 and max sentences per GPU = None
2024-02-19 15:45:16 | INFO | fairseq.trainer | loaded checkpoint ./bart.large.cnn/model.pt (epoch 5 @ 0 updates)
2024-02-19 15:45:16 | INFO | fairseq.trainer | NOTE: your device does NOT support faster training with --fp16, please switch to FP32 which is likely to be faster
2024-02-19 15:45:16 | INFO | fairseq.trainer | loading train data for epoch 1
2024-02-19 15:45:16 | INFO | fairseq.data.data_utils | loaded 637 examples from: ./output/AMI/stage_1/trainer_output/bin/train.source-target.source
2024-02-19 15:45:16 | INFO | fairseq.data.data_utils | loaded 637 examples from: ./output/AMI/stage_1/trainer_output/bin/train.source-target.target
2024-02-19 15:45:16 | INFO | fairseq.tasks.translation | ./output/AMI/stage_1/trainer_output/bin/ train source-target 637 examples
2024-02-19 15:45:16 | INFO | fairseq.trainer | begin training epoch 1
2024-02-19 15:45:19 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 64.0
2024-02-19 15:45:22 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2024-02-19 15:45:25 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2024-02-19 15:45:30 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2024-02-19 15:46:07 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2024-02-19 15:48:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-19 15:48:35 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.264 | nll_loss 4.717 | ppl 26.29 | wps 2520.3 | wpb 543 | bsz 2.1 | num_updates 70
2024-02-19 15:48:35 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-19 15:49:06 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_1/trainer_output/checkpoints/checkpoint_best.pt (epoch 1 @ 70 updates, score 6.264) (writing took 31.26513691805303 seconds)
2024-02-19 15:49:06 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2024-02-19 15:49:06 | INFO | train | epoch 001 | loss 6.991 | nll_loss 5.574 | ppl 47.64 | wps 582.8 | ups 0.32 | wpb 1848.6 | bsz 8.5 | num_updates 70 | lr 4.2e-06 | gnorm 14.91 | clip 100 | loss_scale 4 | train_wall 186 | wall 232
2024-02-19 15:49:06 | INFO | fairseq.trainer | begin training epoch 2
2024-02-19 15:50:23 | INFO | train_inner | epoch 002:     30 / 75 loss=6.642, nll_loss=5.174, ppl=36.09, wps=624.5, ups=0.34, wpb=1860.6, bsz=8.5, num_updates=100, lr=6e-06, gnorm=11.545, clip=100, loss_scale=4, train_wall=253, wall=308
2024-02-19 15:52:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-19 15:52:29 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 5.943 | nll_loss 4.36 | ppl 20.54 | wps 2508.3 | wpb 543 | bsz 2.1 | num_updates 145 | best_loss 5.943
2024-02-19 15:52:29 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-19 15:53:01 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_1/trainer_output/checkpoints/checkpoint_best.pt (epoch 2 @ 145 updates, score 5.943) (writing took 31.496844079345465 seconds)
2024-02-19 15:53:01 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2024-02-19 15:53:01 | INFO | train | epoch 002 | loss 5.623 | nll_loss 4.006 | ppl 16.07 | wps 592.8 | ups 0.32 | wpb 1852.8 | bsz 8.5 | num_updates 145 | lr 8.7e-06 | gnorm 3.456 | clip 100 | loss_scale 4 | train_wall 190 | wall 467
2024-02-19 15:53:01 | INFO | fairseq.trainer | begin training epoch 3
2024-02-19 15:55:22 | INFO | train_inner | epoch 003:     55 / 75 loss=5.197, nll_loss=3.521, ppl=11.48, wps=618.8, ups=0.33, wpb=1851.8, bsz=8.5, num_updates=200, lr=1.2e-05, gnorm=3.245, clip=100, loss_scale=4, train_wall=254, wall=607
2024-02-19 15:56:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-19 15:56:25 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 5.883 | nll_loss 4.266 | ppl 19.24 | wps 2505.9 | wpb 543 | bsz 2.1 | num_updates 220 | best_loss 5.883
2024-02-19 15:56:25 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-19 15:56:50 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_1/trainer_output/checkpoints/checkpoint_best.pt (epoch 3 @ 220 updates, score 5.883) (writing took 24.991603393107653 seconds)
2024-02-19 15:56:50 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2024-02-19 15:56:50 | INFO | train | epoch 003 | loss 4.922 | nll_loss 3.208 | ppl 9.24 | wps 607.8 | ups 0.33 | wpb 1852.8 | bsz 8.5 | num_updates 220 | lr 1.32e-05 | gnorm 3.228 | clip 100 | loss_scale 4 | train_wall 191 | wall 695
2024-02-19 15:56:50 | INFO | fairseq.trainer | begin training epoch 4
2024-02-19 16:00:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-19 16:00:13 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 5.956 | nll_loss 4.324 | ppl 20.02 | wps 2508.9 | wpb 543 | bsz 2.1 | num_updates 295 | best_loss 5.883
2024-02-19 16:00:13 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-19 16:00:31 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_1/trainer_output/checkpoints/checkpoint_last.pt (epoch 4 @ 295 updates, score 5.956) (writing took 17.66868401132524 seconds)
2024-02-19 16:00:31 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2024-02-19 16:00:31 | INFO | train | epoch 004 | loss 4.333 | nll_loss 2.532 | ppl 5.78 | wps 628.2 | ups 0.34 | wpb 1852.8 | bsz 8.5 | num_updates 295 | lr 1.77e-05 | gnorm 3.34 | clip 100 | loss_scale 4 | train_wall 190 | wall 916
2024-02-19 16:00:31 | INFO | fairseq.trainer | begin training epoch 5
2024-02-19 16:00:43 | INFO | train_inner | epoch 005:      5 / 75 loss=4.396, nll_loss=2.605, ppl=6.08, wps=572.6, ups=0.31, wpb=1839.7, bsz=8.5, num_updates=300, lr=1.8e-05, gnorm=3.31, clip=100, loss_scale=4, train_wall=253, wall=929
2024-02-19 16:03:41 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2.0
2024-02-19 16:03:42 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-19 16:03:54 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 6.193 | nll_loss 4.559 | ppl 23.57 | wps 2511.2 | wpb 543 | bsz 2.1 | num_updates 369 | best_loss 5.883
2024-02-19 16:03:54 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 2 runs
2024-02-19 16:03:54 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-19 16:04:12 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_1/trainer_output/checkpoints/checkpoint_last.pt (epoch 5 @ 369 updates, score 6.193) (writing took 17.840406576171517 seconds)
2024-02-19 16:04:12 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2024-02-19 16:04:12 | INFO | train | epoch 005 | loss 3.804 | nll_loss 1.92 | ppl 3.78 | wps 617.2 | ups 0.33 | wpb 1846.5 | bsz 8.4 | num_updates 369 | lr 2.214e-05 | gnorm 3.006 | clip 100 | loss_scale 2 | train_wall 190 | wall 1138
2024-02-19 16:04:12 | INFO | fairseq_cli.train | done training in 1135.9 seconds

2024-02-19 16:04:13 | INFO | fairseq.file_utils | loading archive file ./output/AMI/stage_1/trainer_output
2024-02-19 16:04:15 | INFO | fairseq.tasks.translation | [source] dictionary: 50264 types
2024-02-19 16:04:15 | INFO | fairseq.tasks.translation | [target] dictionary: 50264 types

  0%|          | 0/636 [00:00<?, ?it/s]
  1%|▏         | 8/636 [00:24<32:29,  3.10s/it]
  3%|▎         | 16/636 [00:45<28:49,  2.79s/it]
  4%|▍         | 24/636 [01:08<28:55,  2.84s/it]
  5%|▌         | 32/636 [01:28<27:20,  2.72s/it]
  6%|▋         | 40/636 [01:48<25:51,  2.60s/it]
  8%|▊         | 48/636 [02:09<25:46,  2.63s/it]
  9%|▉         | 56/636 [02:31<25:49,  2.67s/it]
 10%|█         | 64/636 [02:53<25:51,  2.71s/it]
 11%|█▏        | 72/636 [03:15<25:27,  2.71s/it]
 13%|█▎        | 80/636 [03:37<25:05,  2.71s/it]
 14%|█▍        | 88/636 [04:01<25:46,  2.82s/it]
 15%|█▌        | 96/636 [04:23<25:15,  2.81s/it]
 16%|█▋        | 104/636 [04:43<23:55,  2.70s/it]
 18%|█▊        | 112/636 [05:04<23:17,  2.67s/it]
 19%|█▉        | 120/636 [05:25<22:50,  2.66s/it]
 20%|██        | 128/636 [05:44<21:57,  2.59s/it]
 21%|██▏       | 136/636 [06:05<21:41,  2.60s/it]
 23%|██▎       | 144/636 [06:27<21:39,  2.64s/it]
 24%|██▍       | 152/636 [06:49<21:20,  2.65s/it]
 25%|██▌       | 160/636 [07:08<20:29,  2.58s/it]
 26%|██▋       | 168/636 [07:27<19:34,  2.51s/it]
 28%|██▊       | 176/636 [07:47<19:17,  2.52s/it]
 29%|██▉       | 184/636 [08:07<18:53,  2.51s/it]
 30%|███       | 192/636 [08:26<18:12,  2.46s/it]
 31%|███▏      | 200/636 [08:47<18:13,  2.51s/it]
 33%|███▎      | 208/636 [09:08<18:15,  2.56s/it]
 34%|███▍      | 216/636 [09:59<25:52,  3.70s/it]
 35%|███▌      | 224/636 [10:57<32:47,  4.78s/it]
 36%|███▋      | 232/636 [11:56<37:21,  5.55s/it]
 38%|███▊      | 240/636 [12:58<40:58,  6.21s/it]
 39%|███▉      | 248/636 [14:03<43:44,  6.76s/it]
 40%|████      | 256/636 [15:02<44:07,  6.97s/it]
 42%|████▏     | 264/636 [16:05<44:54,  7.24s/it]
 43%|████▎     | 272/636 [17:07<44:52,  7.40s/it]
 44%|████▍     | 280/636 [18:12<45:10,  7.61s/it]
 45%|████▌     | 288/636 [19:14<44:21,  7.65s/it]
 47%|████▋     | 296/636 [20:18<44:00,  7.77s/it]
 48%|████▊     | 304/636 [21:18<42:32,  7.69s/it]
 49%|████▉     | 312/636 [22:20<41:35,  7.70s/it]
 50%|█████     | 320/636 [23:18<39:42,  7.54s/it]
 52%|█████▏    | 328/636 [24:07<36:31,  7.12s/it]
 53%|█████▎    | 336/636 [25:10<36:50,  7.37s/it]
 54%|█████▍    | 344/636 [26:11<36:14,  7.45s/it]
 55%|█████▌    | 352/636 [27:19<36:38,  7.74s/it]
 57%|█████▋    | 360/636 [28:25<36:22,  7.91s/it]
 58%|█████▊    | 368/636 [29:30<35:37,  7.98s/it]
 59%|█████▉    | 376/636 [30:32<34:18,  7.92s/it]
 60%|██████    | 384/636 [31:29<32:13,  7.67s/it]
 62%|██████▏   | 392/636 [32:25<30:20,  7.46s/it]
 63%|██████▎   | 400/636 [33:30<30:10,  7.67s/it]
 64%|██████▍   | 408/636 [34:36<29:44,  7.83s/it]
 65%|██████▌   | 416/636 [35:37<28:26,  7.76s/it]
 67%|██████▋   | 424/636 [36:20<24:56,  7.06s/it]
 68%|██████▊   | 432/636 [36:40<19:23,  5.70s/it]
 69%|██████▉   | 440/636 [37:02<15:37,  4.79s/it]
 70%|███████   | 448/636 [37:21<12:45,  4.07s/it]
 72%|███████▏  | 456/636 [37:41<10:50,  3.62s/it]
 73%|███████▎  | 464/636 [38:02<09:29,  3.31s/it]
 74%|███████▍  | 472/636 [38:22<08:20,  3.05s/it]
 75%|███████▌  | 480/636 [38:42<07:35,  2.92s/it]
 77%|███████▋  | 488/636 [39:04<07:03,  2.86s/it]
 78%|███████▊  | 496/636 [39:26<06:34,  2.82s/it]
 79%|███████▉  | 504/636 [39:50<06:18,  2.87s/it]
 81%|████████  | 512/636 [40:09<05:40,  2.74s/it]
 82%|████████▏ | 520/636 [40:29<05:07,  2.65s/it]
 83%|████████▎ | 528/636 [40:51<04:50,  2.69s/it]
 84%|████████▍ | 536/636 [41:14<04:35,  2.75s/it]
 86%|████████▌ | 544/636 [41:37<04:14,  2.76s/it]
 87%|████████▋ | 552/636 [41:57<03:46,  2.70s/it]
 88%|████████▊ | 560/636 [42:17<03:19,  2.63s/it]
 89%|████████▉ | 568/636 [42:36<02:53,  2.55s/it]
 91%|█████████ | 576/636 [42:54<02:28,  2.48s/it]
 92%|█████████▏| 584/636 [43:12<02:05,  2.42s/it]
 93%|█████████▎| 592/636 [43:32<01:47,  2.44s/it]
 94%|█████████▍| 600/636 [43:52<01:27,  2.43s/it]
 96%|█████████▌| 608/636 [44:09<01:05,  2.35s/it]
 97%|█████████▋| 616/636 [44:28<00:47,  2.36s/it]
 98%|█████████▊| 624/636 [44:49<00:29,  2.45s/it]
 99%|█████████▉| 632/636 [45:07<00:09,  2.39s/it]
100%|██████████| 636/636 [45:07<00:00,  4.26s/it]

  0%|          | 0/121 [00:00<?, ?it/s]
  7%|▋         | 8/121 [00:19<04:37,  2.46s/it]
 13%|█▎        | 16/121 [00:42<04:40,  2.67s/it]
 20%|█▉        | 24/121 [01:02<04:11,  2.60s/it]
 26%|██▋       | 32/121 [01:22<03:47,  2.55s/it]
 33%|███▎      | 40/121 [01:43<03:30,  2.60s/it]
 40%|███▉      | 48/121 [02:04<03:11,  2.62s/it]
 46%|████▋     | 56/121 [02:23<02:43,  2.52s/it]
 53%|█████▎    | 64/121 [02:44<02:26,  2.58s/it]
 60%|█████▉    | 72/121 [03:07<02:09,  2.65s/it]
 66%|██████▌   | 80/121 [03:29<01:49,  2.67s/it]
 73%|███████▎  | 88/121 [03:51<01:29,  2.72s/it]
 79%|███████▉  | 96/121 [04:12<01:07,  2.69s/it]
 86%|████████▌ | 104/121 [04:33<00:45,  2.67s/it]
 93%|█████████▎| 112/121 [04:54<00:23,  2.66s/it]
 99%|█████████▉| 120/121 [05:16<00:02,  2.68s/it]
100%|██████████| 121/121 [05:16<00:00,  2.62s/it]

  0%|          | 0/138 [00:00<?, ?it/s]
  6%|▌         | 8/138 [00:18<05:04,  2.35s/it]
 12%|█▏        | 16/138 [00:41<05:21,  2.64s/it]
 17%|█▋        | 24/138 [01:01<04:55,  2.59s/it]
 23%|██▎       | 32/138 [01:22<04:32,  2.57s/it]
 29%|██▉       | 40/138 [01:42<04:12,  2.57s/it]
 35%|███▍      | 48/138 [02:01<03:44,  2.50s/it]
 41%|████      | 56/138 [02:20<03:22,  2.47s/it]
 46%|████▋     | 64/138 [02:42<03:07,  2.53s/it]
 52%|█████▏    | 72/138 [03:03<02:50,  2.59s/it]
 58%|█████▊    | 80/138 [03:25<02:32,  2.63s/it]
 64%|██████▍   | 88/138 [03:46<02:11,  2.63s/it]
 70%|██████▉   | 96/138 [04:07<01:49,  2.62s/it]
 75%|███████▌  | 104/138 [04:29<01:30,  2.65s/it]
 81%|████████  | 112/138 [04:49<01:07,  2.61s/it]
 87%|████████▋ | 120/138 [05:09<00:46,  2.59s/it]
 93%|█████████▎| 128/138 [05:30<00:25,  2.60s/it]
 99%|█████████▊| 136/138 [05:50<00:05,  2.58s/it]
100%|██████████| 138/138 [05:50<00:00,  2.54s/it]mkdir: cannot create directory ‘./output/AMI/stage_2/trainer_output’: File exists
2024-02-19 17:01:34 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='./output/AMI/stage_2/trainer_output/bin/', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='source', srcdict='dict.txt', target_lang='target', task='translation', tensorboard_logdir=None, testpref=None, tgtdict='dict.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='./output/AMI/stage_2/trainer_output/train.bpe', user_dir=None, validpref='./output/AMI/stage_2/trainer_output/val.bpe', workers=60)
2024-02-19 17:01:35 | INFO | fairseq_cli.preprocess | [source] Dictionary: 50264 types
2024-02-19 17:01:36 | INFO | fairseq_cli.preprocess | [source] ./output/AMI/stage_2/trainer_output/train.bpe.source: 97 sents, 151600 tokens, 0.0% replaced by <unk>
2024-02-19 17:01:36 | INFO | fairseq_cli.preprocess | [source] Dictionary: 50264 types
2024-02-19 17:01:38 | INFO | fairseq_cli.preprocess | [source] ./output/AMI/stage_2/trainer_output/val.bpe.source: 20 sents, 29487 tokens, 0.0% replaced by <unk>
2024-02-19 17:01:38 | INFO | fairseq_cli.preprocess | [target] Dictionary: 50264 types
2024-02-19 17:01:40 | INFO | fairseq_cli.preprocess | [target] ./output/AMI/stage_2/trainer_output/train.bpe.target: 97 sents, 30941 tokens, 0.0% replaced by <unk>
2024-02-19 17:01:40 | INFO | fairseq_cli.preprocess | [target] Dictionary: 50264 types
2024-02-19 17:01:41 | INFO | fairseq_cli.preprocess | [target] ./output/AMI/stage_2/trainer_output/val.bpe.target: 20 sents, 7464 tokens, 0.0% replaced by <unk>
2024-02-19 17:01:41 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to ./output/AMI/stage_2/trainer_output/bin/

CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.
To initialize your shell, run

    $ conda init <SHELL_NAME>

Currently supported shells are:
  - bash
  - fish
  - tcsh
  - xonsh
  - zsh
  - powershell

See 'conda init --help' for more information and options.

IMPORTANT: You may need to close and restart your shell after running 'conda init'.


2024-02-19 17:01:44 | INFO | fairseq_cli.train | Namespace(activation_fn='gelu', adam_betas='(0.9, 0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='bart_large', attention_dropout=0.1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.1, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='./output/AMI/stage_2/trainer_output/bin/', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_layerdrop=0, decoder_layers=12, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=False, decoder_output_dim=1024, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=12, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=False, end_learning_rate=0.0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=True, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[3e-05], lr_scheduler='polynomial_decay', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=2048, max_tokens_valid=2048, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=2, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=1, required_seq_len_multiple=1, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, restore_file='./bart.large.cnn/model.pt', save_dir='./output/AMI/stage_2/trainer_output/checkpoints', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=True, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='source', stop_time_hours=0, target_lang='target', task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, total_num_update=30000, tpu=False, train_subset='train', truncate_source=True, update_freq=[4], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=500, weight_decay=0.01, zero_sharding='none')
2024-02-19 17:01:44 | INFO | fairseq.tasks.translation | [source] dictionary: 50264 types
2024-02-19 17:01:44 | INFO | fairseq.tasks.translation | [target] dictionary: 50264 types
2024-02-19 17:01:44 | INFO | fairseq.data.data_utils | loaded 20 examples from: ./output/AMI/stage_2/trainer_output/bin/valid.source-target.source
2024-02-19 17:01:44 | INFO | fairseq.data.data_utils | loaded 20 examples from: ./output/AMI/stage_2/trainer_output/bin/valid.source-target.target
2024-02-19 17:01:44 | INFO | fairseq.tasks.translation | ./output/AMI/stage_2/trainer_output/bin/ valid source-target 20 examples
2024-02-19 17:02:01 | INFO | fairseq_cli.train | BARTModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50264, 1024, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)
    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (6): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (7): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (8): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (9): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (10): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (11): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50264, 1024, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)
    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (6): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (7): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (8): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (9): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (10): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (11): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=1024, out_features=50264, bias=False)
  )
  (classification_heads): ModuleDict()
)
2024-02-19 17:02:01 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2024-02-19 17:02:01 | INFO | fairseq_cli.train | model: bart_large (BARTModel)
2024-02-19 17:02:01 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2024-02-19 17:02:01 | INFO | fairseq_cli.train | num. model params: 406290432 (num. trained: 406290432)
2024-02-19 17:02:02 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2024-02-19 17:02:02 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2024-02-19 17:02:02 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-02-19 17:02:02 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 23.870 GB ; name = Quadro P6000                            
2024-02-19 17:02:02 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-02-19 17:02:02 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2024-02-19 17:02:02 | INFO | fairseq_cli.train | max tokens per GPU = 2048 and max sentences per GPU = None
2024-02-19 17:02:04 | INFO | fairseq.trainer | loaded checkpoint ./bart.large.cnn/model.pt (epoch 5 @ 0 updates)
2024-02-19 17:02:04 | INFO | fairseq.trainer | NOTE: your device does NOT support faster training with --fp16, please switch to FP32 which is likely to be faster
2024-02-19 17:02:04 | INFO | fairseq.trainer | loading train data for epoch 1
2024-02-19 17:02:04 | INFO | fairseq.data.data_utils | loaded 97 examples from: ./output/AMI/stage_2/trainer_output/bin/train.source-target.source
2024-02-19 17:02:04 | INFO | fairseq.data.data_utils | loaded 97 examples from: ./output/AMI/stage_2/trainer_output/bin/train.source-target.target
2024-02-19 17:02:04 | INFO | fairseq.tasks.translation | ./output/AMI/stage_2/trainer_output/bin/ train source-target 97 examples
2024-02-19 17:02:04 | INFO | fairseq.trainer | begin training epoch 1
2024-02-19 17:02:08 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 64.0
2024-02-19 17:02:11 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2024-02-19 17:02:14 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2024-02-19 17:02:17 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2024-02-19 17:02:20 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2024-02-19 17:02:28 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2.0
2024-02-19 17:02:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-19 17:02:41 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.839 | nll_loss 5.384 | ppl 41.76 | wps 3250.4 | wpb 746.4 | bsz 2 | num_updates 6
2024-02-19 17:02:41 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-19 17:03:13 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_2/trainer_output/checkpoints/checkpoint_best.pt (epoch 1 @ 6 updates, score 6.839) (writing took 31.68855218961835 seconds)
2024-02-19 17:03:13 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2024-02-19 17:03:13 | INFO | train | epoch 001 | loss 6.894 | nll_loss 5.472 | ppl 44.4 | wps 243.5 | ups 0.1 | wpb 2467.5 | bsz 7.7 | num_updates 6 | lr 3.6e-07 | gnorm 35.817 | clip 100 | loss_scale 2 | train_wall 34 | wall 71
2024-02-19 17:03:13 | INFO | fairseq.trainer | begin training epoch 2
2024-02-19 17:03:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-19 17:03:47 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 6.583 | nll_loss 5.09 | ppl 34.06 | wps 3190.9 | wpb 746.4 | bsz 2 | num_updates 18 | best_loss 6.583
2024-02-19 17:03:47 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-19 17:04:18 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_2/trainer_output/checkpoints/checkpoint_best.pt (epoch 2 @ 18 updates, score 6.583) (writing took 31.426803793758154 seconds)
2024-02-19 17:04:18 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2024-02-19 17:04:18 | INFO | train | epoch 002 | loss 6.742 | nll_loss 5.298 | ppl 39.34 | wps 471.6 | ups 0.18 | wpb 2578.4 | bsz 8.1 | num_updates 18 | lr 1.08e-06 | gnorm 26.876 | clip 100 | loss_scale 2 | train_wall 32 | wall 136
2024-02-19 17:04:18 | INFO | fairseq.trainer | begin training epoch 3
2024-02-19 17:04:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-19 17:04:53 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 6.275 | nll_loss 4.763 | ppl 27.14 | wps 3178.6 | wpb 746.4 | bsz 2 | num_updates 30 | best_loss 6.275
2024-02-19 17:04:53 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-19 17:05:20 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_2/trainer_output/checkpoints/checkpoint_best.pt (epoch 3 @ 30 updates, score 6.275) (writing took 27.836370142176747 seconds)
2024-02-19 17:05:20 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2024-02-19 17:05:20 | INFO | train | epoch 003 | loss 6.293 | nll_loss 4.791 | ppl 27.69 | wps 497.6 | ups 0.19 | wpb 2578.4 | bsz 8.1 | num_updates 30 | lr 1.8e-06 | gnorm 8.024 | clip 100 | loss_scale 2 | train_wall 32 | wall 198
2024-02-19 17:05:20 | INFO | fairseq.trainer | begin training epoch 4
2024-02-19 17:05:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-19 17:05:55 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 6.089 | nll_loss 4.573 | ppl 23.8 | wps 3264.2 | wpb 746.4 | bsz 2 | num_updates 42 | best_loss 6.089
2024-02-19 17:05:55 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-19 17:06:26 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_2/trainer_output/checkpoints/checkpoint_best.pt (epoch 4 @ 42 updates, score 6.089) (writing took 31.589603751897812 seconds)
2024-02-19 17:06:26 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2024-02-19 17:06:26 | INFO | train | epoch 004 | loss 5.95 | nll_loss 4.426 | ppl 21.49 | wps 469.2 | ups 0.18 | wpb 2578.4 | bsz 8.1 | num_updates 42 | lr 2.52e-06 | gnorm 4.375 | clip 100 | loss_scale 2 | train_wall 32 | wall 264
2024-02-19 17:06:26 | INFO | fairseq.trainer | begin training epoch 5
2024-02-19 17:06:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-19 17:07:01 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 5.995 | nll_loss 4.449 | ppl 21.85 | wps 3212.1 | wpb 746.4 | bsz 2 | num_updates 54 | best_loss 5.995
2024-02-19 17:07:01 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-19 17:07:32 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_2/trainer_output/checkpoints/checkpoint_best.pt (epoch 5 @ 54 updates, score 5.995) (writing took 31.465653598308563 seconds)
2024-02-19 17:07:32 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2024-02-19 17:07:32 | INFO | train | epoch 005 | loss 5.751 | nll_loss 4.204 | ppl 18.44 | wps 469.9 | ups 0.18 | wpb 2578.4 | bsz 8.1 | num_updates 54 | lr 3.24e-06 | gnorm 3.39 | clip 100 | loss_scale 2 | train_wall 32 | wall 330
2024-02-19 17:07:32 | INFO | fairseq.trainer | begin training epoch 6
2024-02-19 17:08:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-19 17:08:07 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 5.925 | nll_loss 4.357 | ppl 20.49 | wps 3198.4 | wpb 746.4 | bsz 2 | num_updates 66 | best_loss 5.925
2024-02-19 17:08:07 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-19 17:08:39 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_2/trainer_output/checkpoints/checkpoint_best.pt (epoch 6 @ 66 updates, score 5.925) (writing took 32.20908713713288 seconds)
2024-02-19 17:08:39 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2024-02-19 17:08:39 | INFO | train | epoch 006 | loss 5.582 | nll_loss 4.001 | ppl 16.01 | wps 464.8 | ups 0.18 | wpb 2578.4 | bsz 8.1 | num_updates 66 | lr 3.96e-06 | gnorm 2.934 | clip 100 | loss_scale 2 | train_wall 32 | wall 397
2024-02-19 17:08:39 | INFO | fairseq.trainer | begin training epoch 7
2024-02-19 17:09:11 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-19 17:09:13 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 5.859 | nll_loss 4.283 | ppl 19.47 | wps 3219.6 | wpb 746.4 | bsz 2 | num_updates 78 | best_loss 5.859
2024-02-19 17:09:13 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-19 17:09:45 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_2/trainer_output/checkpoints/checkpoint_best.pt (epoch 7 @ 78 updates, score 5.859) (writing took 32.37180353142321 seconds)
2024-02-19 17:09:45 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2024-02-19 17:09:45 | INFO | train | epoch 007 | loss 5.441 | nll_loss 3.833 | ppl 14.25 | wps 463.8 | ups 0.18 | wpb 2578.4 | bsz 8.1 | num_updates 78 | lr 4.68e-06 | gnorm 2.696 | clip 100 | loss_scale 2 | train_wall 32 | wall 463
2024-02-19 17:09:45 | INFO | fairseq.trainer | begin training epoch 8
2024-02-19 17:10:17 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-19 17:10:20 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 5.809 | nll_loss 4.228 | ppl 18.74 | wps 3187.9 | wpb 746.4 | bsz 2 | num_updates 90 | best_loss 5.809
2024-02-19 17:10:20 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-19 17:10:52 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_2/trainer_output/checkpoints/checkpoint_best.pt (epoch 8 @ 90 updates, score 5.809) (writing took 32.069017983973026 seconds)
2024-02-19 17:10:52 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2024-02-19 17:10:52 | INFO | train | epoch 008 | loss 5.329 | nll_loss 3.708 | ppl 13.06 | wps 465.5 | ups 0.18 | wpb 2578.4 | bsz 8.1 | num_updates 90 | lr 5.4e-06 | gnorm 2.644 | clip 100 | loss_scale 2 | train_wall 32 | wall 530
2024-02-19 17:10:52 | INFO | fairseq.trainer | begin training epoch 9
2024-02-19 17:11:19 | INFO | train_inner | epoch 009:     10 / 12 loss=5.864, nll_loss=4.315, ppl=19.91, wps=475.8, ups=0.18, wpb=2576.2, bsz=8.1, num_updates=100, lr=6e-06, gnorm=8.517, clip=100, loss_scale=2, train_wall=267, wall=557
2024-02-19 17:11:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-19 17:11:26 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 5.778 | nll_loss 4.185 | ppl 18.19 | wps 3220.2 | wpb 746.4 | bsz 2 | num_updates 102 | best_loss 5.778
2024-02-19 17:11:26 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-19 17:11:58 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_2/trainer_output/checkpoints/checkpoint_best.pt (epoch 9 @ 102 updates, score 5.778) (writing took 32.15354015864432 seconds)
2024-02-19 17:11:58 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2024-02-19 17:11:58 | INFO | train | epoch 009 | loss 5.207 | nll_loss 3.566 | ppl 11.84 | wps 465.3 | ups 0.18 | wpb 2578.4 | bsz 8.1 | num_updates 102 | lr 6.12e-06 | gnorm 2.556 | clip 100 | loss_scale 2 | train_wall 32 | wall 596
2024-02-19 17:11:58 | INFO | fairseq.trainer | begin training epoch 10
2024-02-19 17:12:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-19 17:12:33 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 5.739 | nll_loss 4.142 | ppl 17.66 | wps 3191 | wpb 746.4 | bsz 2 | num_updates 114 | best_loss 5.739
2024-02-19 17:12:33 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-19 17:13:05 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_2/trainer_output/checkpoints/checkpoint_best.pt (epoch 10 @ 114 updates, score 5.739) (writing took 32.09754430130124 seconds)
2024-02-19 17:13:05 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2024-02-19 17:13:05 | INFO | train | epoch 010 | loss 5.096 | nll_loss 3.439 | ppl 10.85 | wps 465.1 | ups 0.18 | wpb 2578.4 | bsz 8.1 | num_updates 114 | lr 6.84e-06 | gnorm 2.508 | clip 100 | loss_scale 2 | train_wall 32 | wall 663
2024-02-19 17:13:05 | INFO | fairseq.trainer | begin training epoch 11
2024-02-19 17:13:37 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-19 17:13:39 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 5.712 | nll_loss 4.103 | ppl 17.18 | wps 3190.2 | wpb 746.4 | bsz 2 | num_updates 126 | best_loss 5.712
2024-02-19 17:13:39 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-19 17:14:11 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_2/trainer_output/checkpoints/checkpoint_best.pt (epoch 11 @ 126 updates, score 5.712) (writing took 32.111505115404725 seconds)
2024-02-19 17:14:11 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2024-02-19 17:14:11 | INFO | train | epoch 011 | loss 4.987 | nll_loss 3.311 | ppl 9.92 | wps 465.3 | ups 0.18 | wpb 2578.4 | bsz 8.1 | num_updates 126 | lr 7.56e-06 | gnorm 2.524 | clip 100 | loss_scale 2 | train_wall 32 | wall 729
2024-02-19 17:14:11 | INFO | fairseq.trainer | begin training epoch 12
2024-02-19 17:14:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-19 17:14:46 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 5.7 | nll_loss 4.091 | ppl 17.04 | wps 3240.8 | wpb 746.4 | bsz 2 | num_updates 138 | best_loss 5.7
2024-02-19 17:14:46 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-19 17:15:18 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_2/trainer_output/checkpoints/checkpoint_best.pt (epoch 12 @ 138 updates, score 5.7) (writing took 31.9911902975291 seconds)
2024-02-19 17:15:18 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2024-02-19 17:15:18 | INFO | train | epoch 012 | loss 4.867 | nll_loss 3.176 | ppl 9.04 | wps 466.1 | ups 0.18 | wpb 2578.4 | bsz 8.1 | num_updates 138 | lr 8.28e-06 | gnorm 2.507 | clip 100 | loss_scale 2 | train_wall 32 | wall 796
2024-02-19 17:15:18 | INFO | fairseq.trainer | begin training epoch 13
2024-02-19 17:15:50 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-19 17:15:52 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 5.689 | nll_loss 4.069 | ppl 16.78 | wps 3238.4 | wpb 746.4 | bsz 2 | num_updates 150 | best_loss 5.689
2024-02-19 17:15:52 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-19 17:16:24 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_2/trainer_output/checkpoints/checkpoint_best.pt (epoch 13 @ 150 updates, score 5.689) (writing took 31.834894498810172 seconds)
2024-02-19 17:16:24 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2024-02-19 17:16:24 | INFO | train | epoch 013 | loss 4.765 | nll_loss 3.057 | ppl 8.32 | wps 467.4 | ups 0.18 | wpb 2578.4 | bsz 8.1 | num_updates 150 | lr 9e-06 | gnorm 2.521 | clip 100 | loss_scale 2 | train_wall 32 | wall 862
2024-02-19 17:16:24 | INFO | fairseq.trainer | begin training epoch 14
2024-02-19 17:16:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-19 17:16:58 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 5.687 | nll_loss 4.071 | ppl 16.81 | wps 3191.9 | wpb 746.4 | bsz 2 | num_updates 162 | best_loss 5.687
2024-02-19 17:16:58 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-19 17:17:30 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_2/trainer_output/checkpoints/checkpoint_best.pt (epoch 14 @ 162 updates, score 5.687) (writing took 31.897154543548822 seconds)
2024-02-19 17:17:30 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2024-02-19 17:17:30 | INFO | train | epoch 014 | loss 4.654 | nll_loss 2.931 | ppl 7.63 | wps 466.5 | ups 0.18 | wpb 2578.4 | bsz 8.1 | num_updates 162 | lr 9.72e-06 | gnorm 2.506 | clip 100 | loss_scale 2 | train_wall 32 | wall 928
2024-02-19 17:17:30 | INFO | fairseq.trainer | begin training epoch 15
2024-02-19 17:18:02 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-19 17:18:05 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 5.678 | nll_loss 4.05 | ppl 16.57 | wps 3217.6 | wpb 746.4 | bsz 2 | num_updates 174 | best_loss 5.678
2024-02-19 17:18:05 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-19 17:18:37 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_2/trainer_output/checkpoints/checkpoint_best.pt (epoch 15 @ 174 updates, score 5.678) (writing took 32.03561785072088 seconds)
2024-02-19 17:18:37 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2024-02-19 17:18:37 | INFO | train | epoch 015 | loss 4.541 | nll_loss 2.797 | ppl 6.95 | wps 466 | ups 0.18 | wpb 2578.4 | bsz 8.1 | num_updates 174 | lr 1.044e-05 | gnorm 2.518 | clip 100 | loss_scale 2 | train_wall 32 | wall 995
2024-02-19 17:18:37 | INFO | fairseq.trainer | begin training epoch 16
2024-02-19 17:19:09 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-19 17:19:11 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 5.678 | nll_loss 4.044 | ppl 16.5 | wps 3227.3 | wpb 746.4 | bsz 2 | num_updates 186 | best_loss 5.678
2024-02-19 17:19:11 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-19 17:19:43 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_2/trainer_output/checkpoints/checkpoint_best.pt (epoch 16 @ 186 updates, score 5.678) (writing took 31.983690259978175 seconds)
2024-02-19 17:19:43 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2024-02-19 17:19:43 | INFO | train | epoch 016 | loss 4.453 | nll_loss 2.698 | ppl 6.49 | wps 466.5 | ups 0.18 | wpb 2578.4 | bsz 8.1 | num_updates 186 | lr 1.116e-05 | gnorm 2.576 | clip 100 | loss_scale 2 | train_wall 32 | wall 1061
2024-02-19 17:19:43 | INFO | fairseq.trainer | begin training epoch 17
2024-02-19 17:20:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-19 17:20:17 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 5.681 | nll_loss 4.04 | ppl 16.45 | wps 3223.9 | wpb 746.4 | bsz 2 | num_updates 198 | best_loss 5.678
2024-02-19 17:20:17 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 2 runs
2024-02-19 17:20:17 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-19 17:20:35 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_2/trainer_output/checkpoints/checkpoint_last.pt (epoch 17 @ 198 updates, score 5.681) (writing took 18.05970534682274 seconds)
2024-02-19 17:20:35 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2024-02-19 17:20:35 | INFO | train | epoch 017 | loss 4.338 | nll_loss 2.565 | ppl 5.92 | wps 590.4 | ups 0.23 | wpb 2578.4 | bsz 8.1 | num_updates 198 | lr 1.188e-05 | gnorm 2.566 | clip 100 | loss_scale 2 | train_wall 32 | wall 1113
2024-02-19 17:20:35 | INFO | fairseq_cli.train | done training in 1111.4 seconds

2024-02-19 17:20:36 | INFO | fairseq.file_utils | loading archive file ./output/AMI/stage_2/trainer_output
2024-02-19 17:20:38 | INFO | fairseq.tasks.translation | [source] dictionary: 50264 types
2024-02-19 17:20:38 | INFO | fairseq.tasks.translation | [target] dictionary: 50264 types

  0%|          | 0/19 [00:00<?, ?it/s]
 42%|████▏     | 8/19 [02:47<03:50, 20.93s/it]
 84%|████████▍ | 16/19 [05:59<01:08, 22.72s/it]
100%|██████████| 19/19 [05:59<00:00, 18.90s/it]
2024-02-19 17:28:17,800 [MainThread  ] [INFO ]  Writing summaries.
2024-02-19 17:28:17 | INFO | global | Writing summaries.
2024-02-19 17:28:17,800 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmpbh8re4yc/system and model files to /tmp/tmpbh8re4yc/model.
2024-02-19 17:28:17 | INFO | global | Processing summaries. Saving system files to /tmp/tmpbh8re4yc/system and model files to /tmp/tmpbh8re4yc/model.
2024-02-19 17:28:17,800 [MainThread  ] [INFO ]  Processing files in ./output/AMI/stage_2/rouge_log/candidate.
2024-02-19 17:28:17 | INFO | global | Processing files in ./output/AMI/stage_2/rouge_log/candidate.
2024-02-19 17:28:17,800 [MainThread  ] [INFO ]  Processing 000000_candidate.txt.
2024-02-19 17:28:17 | INFO | global | Processing 000000_candidate.txt.
2024-02-19 17:28:17,800 [MainThread  ] [INFO ]  Processing 000001_candidate.txt.
2024-02-19 17:28:17 | INFO | global | Processing 000001_candidate.txt.
2024-02-19 17:28:17,800 [MainThread  ] [INFO ]  Processing 000002_candidate.txt.
2024-02-19 17:28:17 | INFO | global | Processing 000002_candidate.txt.
2024-02-19 17:28:17,801 [MainThread  ] [INFO ]  Processing 000003_candidate.txt.
2024-02-19 17:28:17 | INFO | global | Processing 000003_candidate.txt.
2024-02-19 17:28:17,801 [MainThread  ] [INFO ]  Processing 000004_candidate.txt.
2024-02-19 17:28:17 | INFO | global | Processing 000004_candidate.txt.
2024-02-19 17:28:17,801 [MainThread  ] [INFO ]  Processing 000005_candidate.txt.
2024-02-19 17:28:17 | INFO | global | Processing 000005_candidate.txt.
2024-02-19 17:28:17,801 [MainThread  ] [INFO ]  Processing 000006_candidate.txt.
2024-02-19 17:28:17 | INFO | global | Processing 000006_candidate.txt.
2024-02-19 17:28:17,801 [MainThread  ] [INFO ]  Processing 000007_candidate.txt.
2024-02-19 17:28:17 | INFO | global | Processing 000007_candidate.txt.
2024-02-19 17:28:17,801 [MainThread  ] [INFO ]  Processing 000008_candidate.txt.
2024-02-19 17:28:17 | INFO | global | Processing 000008_candidate.txt.
2024-02-19 17:28:17,801 [MainThread  ] [INFO ]  Processing 000009_candidate.txt.
2024-02-19 17:28:17 | INFO | global | Processing 000009_candidate.txt.
2024-02-19 17:28:17,802 [MainThread  ] [INFO ]  Processing 000010_candidate.txt.
2024-02-19 17:28:17 | INFO | global | Processing 000010_candidate.txt.
2024-02-19 17:28:17,802 [MainThread  ] [INFO ]  Processing 000011_candidate.txt.
2024-02-19 17:28:17 | INFO | global | Processing 000011_candidate.txt.
2024-02-19 17:28:17,802 [MainThread  ] [INFO ]  Processing 000012_candidate.txt.
2024-02-19 17:28:17 | INFO | global | Processing 000012_candidate.txt.
2024-02-19 17:28:17,802 [MainThread  ] [INFO ]  Processing 000013_candidate.txt.
2024-02-19 17:28:17 | INFO | global | Processing 000013_candidate.txt.
2024-02-19 17:28:17,802 [MainThread  ] [INFO ]  Processing 000014_candidate.txt.
2024-02-19 17:28:17 | INFO | global | Processing 000014_candidate.txt.
2024-02-19 17:28:17,802 [MainThread  ] [INFO ]  Processing 000015_candidate.txt.
2024-02-19 17:28:17 | INFO | global | Processing 000015_candidate.txt.
2024-02-19 17:28:17,802 [MainThread  ] [INFO ]  Processing 000016_candidate.txt.
2024-02-19 17:28:17 | INFO | global | Processing 000016_candidate.txt.
2024-02-19 17:28:17,802 [MainThread  ] [INFO ]  Processing 000017_candidate.txt.
2024-02-19 17:28:17 | INFO | global | Processing 000017_candidate.txt.
2024-02-19 17:28:17,803 [MainThread  ] [INFO ]  Processing 000018_candidate.txt.
2024-02-19 17:28:17 | INFO | global | Processing 000018_candidate.txt.
2024-02-19 17:28:17,803 [MainThread  ] [INFO ]  Processing 000019_candidate.txt.
2024-02-19 17:28:17 | INFO | global | Processing 000019_candidate.txt.
2024-02-19 17:28:17,803 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpbh8re4yc/system.
2024-02-19 17:28:17 | INFO | global | Saved processed files to /tmp/tmpbh8re4yc/system.
2024-02-19 17:28:17,803 [MainThread  ] [INFO ]  Processing files in ./output/AMI/stage_2/rouge_log/reference.
2024-02-19 17:28:17 | INFO | global | Processing files in ./output/AMI/stage_2/rouge_log/reference.
2024-02-19 17:28:17,803 [MainThread  ] [INFO ]  Processing 000000_reference.txt.
2024-02-19 17:28:17 | INFO | global | Processing 000000_reference.txt.
2024-02-19 17:28:17,803 [MainThread  ] [INFO ]  Processing 000001_reference.txt.
2024-02-19 17:28:17 | INFO | global | Processing 000001_reference.txt.
2024-02-19 17:28:17,803 [MainThread  ] [INFO ]  Processing 000002_reference.txt.
2024-02-19 17:28:17 | INFO | global | Processing 000002_reference.txt.
2024-02-19 17:28:17,803 [MainThread  ] [INFO ]  Processing 000003_reference.txt.
2024-02-19 17:28:17 | INFO | global | Processing 000003_reference.txt.
2024-02-19 17:28:17,803 [MainThread  ] [INFO ]  Processing 000004_reference.txt.
2024-02-19 17:28:17 | INFO | global | Processing 000004_reference.txt.
2024-02-19 17:28:17,803 [MainThread  ] [INFO ]  Processing 000005_reference.txt.
2024-02-19 17:28:17 | INFO | global | Processing 000005_reference.txt.
2024-02-19 17:28:17,804 [MainThread  ] [INFO ]  Processing 000006_reference.txt.
2024-02-19 17:28:17 | INFO | global | Processing 000006_reference.txt.
2024-02-19 17:28:17,804 [MainThread  ] [INFO ]  Processing 000007_reference.txt.
2024-02-19 17:28:17 | INFO | global | Processing 000007_reference.txt.
2024-02-19 17:28:17,804 [MainThread  ] [INFO ]  Processing 000008_reference.txt.
2024-02-19 17:28:17 | INFO | global | Processing 000008_reference.txt.
2024-02-19 17:28:17,804 [MainThread  ] [INFO ]  Processing 000009_reference.txt.
2024-02-19 17:28:17 | INFO | global | Processing 000009_reference.txt.
2024-02-19 17:28:17,804 [MainThread  ] [INFO ]  Processing 000010_reference.txt.
2024-02-19 17:28:17 | INFO | global | Processing 000010_reference.txt.
2024-02-19 17:28:17,804 [MainThread  ] [INFO ]  Processing 000011_reference.txt.
2024-02-19 17:28:17 | INFO | global | Processing 000011_reference.txt.
2024-02-19 17:28:17,804 [MainThread  ] [INFO ]  Processing 000012_reference.txt.
2024-02-19 17:28:17 | INFO | global | Processing 000012_reference.txt.
2024-02-19 17:28:17,805 [MainThread  ] [INFO ]  Processing 000013_reference.txt.
2024-02-19 17:28:17 | INFO | global | Processing 000013_reference.txt.
2024-02-19 17:28:17,805 [MainThread  ] [INFO ]  Processing 000014_reference.txt.
2024-02-19 17:28:17 | INFO | global | Processing 000014_reference.txt.
2024-02-19 17:28:17,805 [MainThread  ] [INFO ]  Processing 000015_reference.txt.
2024-02-19 17:28:17 | INFO | global | Processing 000015_reference.txt.
2024-02-19 17:28:17,805 [MainThread  ] [INFO ]  Processing 000016_reference.txt.
2024-02-19 17:28:17 | INFO | global | Processing 000016_reference.txt.
2024-02-19 17:28:17,805 [MainThread  ] [INFO ]  Processing 000017_reference.txt.
2024-02-19 17:28:17 | INFO | global | Processing 000017_reference.txt.
2024-02-19 17:28:17,805 [MainThread  ] [INFO ]  Processing 000018_reference.txt.
2024-02-19 17:28:17 | INFO | global | Processing 000018_reference.txt.
2024-02-19 17:28:17,805 [MainThread  ] [INFO ]  Processing 000019_reference.txt.
2024-02-19 17:28:17 | INFO | global | Processing 000019_reference.txt.
2024-02-19 17:28:17,806 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpbh8re4yc/model.
2024-02-19 17:28:17 | INFO | global | Saved processed files to /tmp/tmpbh8re4yc/model.
2024-02-19 17:28:17,808 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmp6s33r6_f/rouge_conf.xml
2024-02-19 17:28:17 | INFO | global | Written ROUGE configuration to /tmp/tmp6s33r6_f/rouge_conf.xml
2024-02-19 17:28:17,808 [MainThread  ] [INFO ]  Running ROUGE with command /home/is/kaifan-l/private_room/proj-repos/Summ-N/ThirdParty/ROUGE/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/is/kaifan-l/private_room/proj-repos/Summ-N/ThirdParty/ROUGE/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmp6s33r6_f/rouge_conf.xml
2024-02-19 17:28:17 | INFO | global | Running ROUGE with command /home/is/kaifan-l/private_room/proj-repos/Summ-N/ThirdParty/ROUGE/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/is/kaifan-l/private_room/proj-repos/Summ-N/ThirdParty/ROUGE/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmp6s33r6_f/rouge_conf.xml
Can't locate XML/Parser.pm in @INC (you may need to install the XML::Parser module) (@INC contains: /home/is/kaifan-l/private_room/proj-repos/Summ-N/ThirdParty/ROUGE/ROUGE-1.5.5 /etc/perl /usr/local/lib/x86_64-linux-gnu/perl/5.34.0 /usr/local/share/perl/5.34.0 /usr/lib/x86_64-linux-gnu/perl5/5.34 /usr/share/perl5 /usr/lib/x86_64-linux-gnu/perl-base /usr/lib/x86_64-linux-gnu/perl/5.34 /usr/share/perl/5.34 /usr/local/lib/site_perl) at /home/is/kaifan-l/private_room/proj-repos/Summ-N/ThirdParty/ROUGE/ROUGE-1.5.5/XML/DOM.pm line 41.
BEGIN failed--compilation aborted at /home/is/kaifan-l/private_room/proj-repos/Summ-N/ThirdParty/ROUGE/ROUGE-1.5.5/XML/DOM.pm line 70.
Compilation failed in require at /home/is/kaifan-l/private_room/proj-repos/Summ-N/ThirdParty/ROUGE/ROUGE-1.5.5/ROUGE-1.5.5.pl line 177.
BEGIN failed--compilation aborted at /home/is/kaifan-l/private_room/proj-repos/Summ-N/ThirdParty/ROUGE/ROUGE-1.5.5/ROUGE-1.5.5.pl line 177.
Finish loading stage 1 dataset!
Train size: 637
Val size: 122
Test size: 139
Finish loading stage 1 dataset!
Finish loading stage 2 dataset!
Train size: 97
Val size: 20
Test size: 20
Traceback (most recent call last):
  File "run.py", line 135, in <module>
    rouge_scores = rouge(cur_target['test'], cur_hypo['test'], rouge_folder)
  File "/home/is/kaifan-l/private_room/proj-repos/Summ-N/utils/AnyROUGE.py", line 36, in rouge
    rouge_results = r.convert_and_evaluate()
  File "/home/is/kaifan-l/miniconda3/envs/SummN/lib/python3.7/site-packages/pyrouge/Rouge155.py", line 361, in convert_and_evaluate
    rouge_output = self.evaluate(system_id, rouge_args)
  File "/home/is/kaifan-l/miniconda3/envs/SummN/lib/python3.7/site-packages/pyrouge/Rouge155.py", line 336, in evaluate
    rouge_output = check_output(command).decode("UTF-8")
  File "/home/is/kaifan-l/miniconda3/envs/SummN/lib/python3.7/subprocess.py", line 411, in check_output
    **kwargs).stdout
  File "/home/is/kaifan-l/miniconda3/envs/SummN/lib/python3.7/subprocess.py", line 512, in run
    output=stdout, stderr=stderr)
subprocess.CalledProcessError: Command '['/home/is/kaifan-l/private_room/proj-repos/Summ-N/ThirdParty/ROUGE/ROUGE-1.5.5/ROUGE-1.5.5.pl', '-e', '/home/is/kaifan-l/private_room/proj-repos/Summ-N/ThirdParty/ROUGE/ROUGE-1.5.5/data', '-c', '95', '-2', '-1', '-U', '-r', '1000', '-n', '4', '-w', '1.2', '-a', '-m', '/tmp/tmp6s33r6_f/rouge_conf.xml']' returned non-zero exit status 2.
