nohup: ignoring input
Finish loading stage 0 dataset!
Train size: 97
Val size: 20
Test size: 20
Start target matching of Stage 1. This may take several minutes.
[nltk_data] Downloading package punkt to
[nltk_data]     /home/is/kaifan-l/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
[nltk_data] Downloading package punkt to
[nltk_data]     /home/is/kaifan-l/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
0it [00:00, ?it/s]637it [00:00, 719184.83it/s]
0it [00:00, ?it/s]122it [00:00, 564173.20it/s]
0it [00:00, ?it/s]139it [00:00, 587709.94it/s]mkdir: cannot create directory ‘./output/AMI/stage_1/trainer_output’: File exists
2024-02-18 19:56:40 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='./output/AMI/stage_1/trainer_output/bin/', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='source', srcdict='dict.txt', target_lang='target', task='translation', tensorboard_logdir=None, testpref=None, tgtdict='dict.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='./output/AMI/stage_1/trainer_output/train.bpe', user_dir=None, validpref='./output/AMI/stage_1/trainer_output/val.bpe', workers=60)
2024-02-18 19:56:40 | INFO | fairseq_cli.preprocess | [source] Dictionary: 50264 types
2024-02-18 19:56:42 | INFO | fairseq_cli.preprocess | [source] ./output/AMI/stage_1/trainer_output/train.bpe.source: 637 sents, 592982 tokens, 0.0% replaced by <unk>
2024-02-18 19:56:42 | INFO | fairseq_cli.preprocess | [source] Dictionary: 50264 types
2024-02-18 19:56:43 | INFO | fairseq_cli.preprocess | [source] ./output/AMI/stage_1/trainer_output/val.bpe.source: 122 sents, 113716 tokens, 0.0% replaced by <unk>
2024-02-18 19:56:43 | INFO | fairseq_cli.preprocess | [target] Dictionary: 50264 types
2024-02-18 19:56:45 | INFO | fairseq_cli.preprocess | [target] ./output/AMI/stage_1/trainer_output/train.bpe.target: 637 sents, 138962 tokens, 0.0% replaced by <unk>
2024-02-18 19:56:45 | INFO | fairseq_cli.preprocess | [target] Dictionary: 50264 types
2024-02-18 19:56:47 | INFO | fairseq_cli.preprocess | [target] ./output/AMI/stage_1/trainer_output/val.bpe.target: 122 sents, 31493 tokens, 0.0% replaced by <unk>
2024-02-18 19:56:47 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to ./output/AMI/stage_1/trainer_output/bin/

CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.
To initialize your shell, run

    $ conda init <SHELL_NAME>

Currently supported shells are:
  - bash
  - fish
  - tcsh
  - xonsh
  - zsh
  - powershell

See 'conda init --help' for more information and options.

IMPORTANT: You may need to close and restart your shell after running 'conda init'.


2024-02-18 19:56:49 | INFO | fairseq_cli.train | Namespace(activation_fn='gelu', adam_betas='(0.9, 0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='bart_large', attention_dropout=0.1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.1, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='./output/AMI/stage_1/trainer_output/bin/', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_layerdrop=0, decoder_layers=12, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=False, decoder_output_dim=1024, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=12, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=False, end_learning_rate=0.0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=True, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[3e-05], lr_scheduler='polynomial_decay', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=2048, max_tokens_valid=2048, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=2, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=1, required_seq_len_multiple=1, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, restore_file='./bart.large.cnn/model.pt', save_dir='./output/AMI/stage_1/trainer_output/checkpoints', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=True, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='source', stop_time_hours=0, target_lang='target', task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, total_num_update=30000, tpu=False, train_subset='train', truncate_source=True, update_freq=[4], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=500, weight_decay=0.01, zero_sharding='none')
2024-02-18 19:56:49 | INFO | fairseq.tasks.translation | [source] dictionary: 50264 types
2024-02-18 19:56:49 | INFO | fairseq.tasks.translation | [target] dictionary: 50264 types
2024-02-18 19:56:49 | INFO | fairseq.data.data_utils | loaded 122 examples from: ./output/AMI/stage_1/trainer_output/bin/valid.source-target.source
2024-02-18 19:56:49 | INFO | fairseq.data.data_utils | loaded 122 examples from: ./output/AMI/stage_1/trainer_output/bin/valid.source-target.target
2024-02-18 19:56:49 | INFO | fairseq.tasks.translation | ./output/AMI/stage_1/trainer_output/bin/ valid source-target 122 examples
2024-02-18 19:57:06 | INFO | fairseq_cli.train | BARTModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50264, 1024, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)
    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (6): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (7): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (8): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (9): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (10): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (11): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50264, 1024, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)
    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (6): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (7): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (8): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (9): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (10): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (11): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=1024, out_features=50264, bias=False)
  )
  (classification_heads): ModuleDict()
)
2024-02-18 19:57:06 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2024-02-18 19:57:06 | INFO | fairseq_cli.train | model: bart_large (BARTModel)
2024-02-18 19:57:06 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2024-02-18 19:57:06 | INFO | fairseq_cli.train | num. model params: 406290432 (num. trained: 406290432)
2024-02-18 19:57:07 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2024-02-18 19:57:07 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2024-02-18 19:57:07 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-02-18 19:57:07 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 23.870 GB ; name = Quadro P6000                            
2024-02-18 19:57:07 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-02-18 19:57:07 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2024-02-18 19:57:07 | INFO | fairseq_cli.train | max tokens per GPU = 2048 and max sentences per GPU = None
2024-02-18 19:57:09 | INFO | fairseq.trainer | loaded checkpoint ./bart.large.cnn/model.pt (epoch 5 @ 0 updates)
2024-02-18 19:57:09 | INFO | fairseq.trainer | NOTE: your device does NOT support faster training with --fp16, please switch to FP32 which is likely to be faster
2024-02-18 19:57:09 | INFO | fairseq.trainer | loading train data for epoch 1
2024-02-18 19:57:09 | INFO | fairseq.data.data_utils | loaded 637 examples from: ./output/AMI/stage_1/trainer_output/bin/train.source-target.source
2024-02-18 19:57:09 | INFO | fairseq.data.data_utils | loaded 637 examples from: ./output/AMI/stage_1/trainer_output/bin/train.source-target.target
2024-02-18 19:57:09 | INFO | fairseq.tasks.translation | ./output/AMI/stage_1/trainer_output/bin/ train source-target 637 examples
2024-02-18 19:57:09 | INFO | fairseq.trainer | begin training epoch 1
2024-02-18 19:57:12 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 64.0
2024-02-18 19:57:15 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2024-02-18 19:57:18 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2024-02-18 19:57:23 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2024-02-18 19:58:00 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2024-02-18 20:00:15 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-18 20:00:28 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.264 | nll_loss 4.717 | ppl 26.29 | wps 2520.1 | wpb 543 | bsz 2.1 | num_updates 70
2024-02-18 20:00:28 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-18 20:00:59 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_1/trainer_output/checkpoints/checkpoint_best.pt (epoch 1 @ 70 updates, score 6.264) (writing took 31.31545333378017 seconds)
2024-02-18 20:00:59 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2024-02-18 20:00:59 | INFO | train | epoch 001 | loss 6.991 | nll_loss 5.574 | ppl 47.64 | wps 583.2 | ups 0.32 | wpb 1848.6 | bsz 8.5 | num_updates 70 | lr 4.2e-06 | gnorm 14.91 | clip 100 | loss_scale 4 | train_wall 186 | wall 232
2024-02-18 20:00:59 | INFO | fairseq.trainer | begin training epoch 2
2024-02-18 20:02:15 | INFO | train_inner | epoch 002:     30 / 75 loss=6.642, nll_loss=5.174, ppl=36.09, wps=626.1, ups=0.34, wpb=1860.6, bsz=8.5, num_updates=100, lr=6e-06, gnorm=11.545, clip=100, loss_scale=4, train_wall=253, wall=308
2024-02-18 20:04:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-18 20:04:20 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 5.943 | nll_loss 4.36 | ppl 20.54 | wps 2499 | wpb 543 | bsz 2.1 | num_updates 145 | best_loss 5.943
2024-02-18 20:04:20 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-18 20:04:55 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_1/trainer_output/checkpoints/checkpoint_best.pt (epoch 2 @ 145 updates, score 5.943) (writing took 35.680898640304804 seconds)
2024-02-18 20:04:55 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2024-02-18 20:04:55 | INFO | train | epoch 002 | loss 5.623 | nll_loss 4.006 | ppl 16.07 | wps 588.6 | ups 0.32 | wpb 1852.8 | bsz 8.5 | num_updates 145 | lr 8.7e-06 | gnorm 3.456 | clip 100 | loss_scale 4 | train_wall 187 | wall 468
2024-02-18 20:04:55 | INFO | fairseq.trainer | begin training epoch 3
2024-02-18 20:07:14 | INFO | train_inner | epoch 003:     55 / 75 loss=5.197, nll_loss=3.521, ppl=11.48, wps=618.5, ups=0.33, wpb=1851.8, bsz=8.5, num_updates=200, lr=1.2e-05, gnorm=3.245, clip=100, loss_scale=4, train_wall=250, wall=607
2024-02-18 20:08:03 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-18 20:08:16 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 5.883 | nll_loss 4.266 | ppl 19.24 | wps 2500.2 | wpb 543 | bsz 2.1 | num_updates 220 | best_loss 5.883
2024-02-18 20:08:16 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-18 20:08:48 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_1/trainer_output/checkpoints/checkpoint_best.pt (epoch 3 @ 220 updates, score 5.883) (writing took 31.945519728586078 seconds)
2024-02-18 20:08:48 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2024-02-18 20:08:48 | INFO | train | epoch 003 | loss 4.922 | nll_loss 3.208 | ppl 9.24 | wps 596.9 | ups 0.32 | wpb 1852.8 | bsz 8.5 | num_updates 220 | lr 1.32e-05 | gnorm 3.228 | clip 100 | loss_scale 4 | train_wall 187 | wall 701
2024-02-18 20:08:48 | INFO | fairseq.trainer | begin training epoch 4
2024-02-18 20:11:58 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-18 20:12:11 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 5.956 | nll_loss 4.324 | ppl 20.02 | wps 2472.3 | wpb 543 | bsz 2.1 | num_updates 295 | best_loss 5.883
2024-02-18 20:12:11 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-18 20:12:21 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_1/trainer_output/checkpoints/checkpoint_last.pt (epoch 4 @ 295 updates, score 5.956) (writing took 10.108793253079057 seconds)
2024-02-18 20:12:21 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2024-02-18 20:12:21 | INFO | train | epoch 004 | loss 4.333 | nll_loss 2.532 | ppl 5.78 | wps 651.8 | ups 0.35 | wpb 1852.8 | bsz 8.5 | num_updates 295 | lr 1.77e-05 | gnorm 3.34 | clip 100 | loss_scale 4 | train_wall 190 | wall 914
2024-02-18 20:12:21 | INFO | fairseq.trainer | begin training epoch 5
2024-02-18 20:12:34 | INFO | train_inner | epoch 005:      5 / 75 loss=4.396, nll_loss=2.605, ppl=6.08, wps=575.5, ups=0.31, wpb=1839.7, bsz=8.5, num_updates=300, lr=1.8e-05, gnorm=3.31, clip=100, loss_scale=4, train_wall=251, wall=927
2024-02-18 20:15:33 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2.0
2024-02-18 20:15:33 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-18 20:15:46 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 6.193 | nll_loss 4.559 | ppl 23.57 | wps 2477.3 | wpb 543 | bsz 2.1 | num_updates 369 | best_loss 5.883
2024-02-18 20:15:46 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 2 runs
2024-02-18 20:15:46 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-18 20:15:57 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_1/trainer_output/checkpoints/checkpoint_last.pt (epoch 5 @ 369 updates, score 6.193) (writing took 10.869099378585815 seconds)
2024-02-18 20:15:57 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2024-02-18 20:15:57 | INFO | train | epoch 005 | loss 3.804 | nll_loss 1.92 | ppl 3.78 | wps 633.5 | ups 0.34 | wpb 1846.5 | bsz 8.4 | num_updates 369 | lr 2.214e-05 | gnorm 3.006 | clip 100 | loss_scale 2 | train_wall 191 | wall 1130
2024-02-18 20:15:57 | INFO | fairseq_cli.train | done training in 1127.9 seconds

2024-02-18 20:15:58 | INFO | fairseq.file_utils | loading archive file ./output/AMI/stage_1/trainer_output
2024-02-18 20:16:01 | INFO | fairseq.tasks.translation | [source] dictionary: 50264 types
2024-02-18 20:16:01 | INFO | fairseq.tasks.translation | [target] dictionary: 50264 types
  0%|          | 0/636 [00:00<?, ?it/s]  1%|▏         | 8/636 [00:26<34:13,  3.27s/it]  3%|▎         | 16/636 [00:47<30:29,  2.95s/it]  4%|▍         | 24/636 [01:12<30:49,  3.02s/it]  5%|▌         | 32/636 [01:35<29:37,  2.94s/it]  6%|▋         | 40/636 [01:57<28:24,  2.86s/it]  8%|▊         | 48/636 [02:21<28:34,  2.92s/it]  9%|▉         | 56/636 [02:46<28:45,  2.98s/it] 10%|█         | 64/636 [03:10<28:44,  3.02s/it] 11%|█▏        | 72/636 [03:35<28:34,  3.04s/it] 13%|█▎        | 80/636 [04:00<28:17,  3.05s/it] 14%|█▍        | 88/636 [04:27<28:58,  3.17s/it] 15%|█▌        | 96/636 [04:53<28:29,  3.17s/it] 16%|█▋        | 104/636 [05:15<27:01,  3.05s/it] 18%|█▊        | 112/636 [05:38<26:18,  3.01s/it] 19%|█▉        | 120/636 [06:03<26:04,  3.03s/it] 20%|██        | 128/636 [06:23<24:12,  2.86s/it] 21%|██▏       | 136/636 [06:44<23:14,  2.79s/it] 23%|██▎       | 144/636 [07:05<22:40,  2.77s/it] 24%|██▍       | 152/636 [07:26<21:57,  2.72s/it] 25%|██▌       | 160/636 [07:46<20:52,  2.63s/it] 26%|██▋       | 168/636 [08:04<19:48,  2.54s/it] 28%|██▊       | 176/636 [08:24<19:23,  2.53s/it] 29%|██▉       | 184/636 [08:44<18:56,  2.52s/it] 30%|███       | 192/636 [09:03<18:10,  2.46s/it] 31%|███▏      | 200/636 [09:23<18:11,  2.50s/it] 33%|███▎      | 208/636 [09:45<18:13,  2.55s/it] 34%|███▍      | 216/636 [10:06<18:11,  2.60s/it] 35%|███▌      | 224/636 [10:26<17:35,  2.56s/it] 36%|███▋      | 232/636 [10:46<17:07,  2.54s/it] 38%|███▊      | 240/636 [11:07<16:50,  2.55s/it] 39%|███▉      | 248/636 [11:28<16:46,  2.59s/it] 40%|████      | 256/636 [11:49<16:23,  2.59s/it] 42%|████▏     | 264/636 [12:13<16:48,  2.71s/it] 43%|████▎     | 272/636 [12:43<18:25,  3.04s/it] 44%|████▍     | 280/636 [13:45<26:25,  4.45s/it] 45%|████▌     | 288/636 [14:46<31:09,  5.37s/it] 47%|████▋     | 296/636 [15:48<34:40,  6.12s/it] 48%|████▊     | 304/636 [16:47<35:48,  6.47s/it] 49%|████▉     | 312/636 [17:48<36:47,  6.81s/it] 50%|█████     | 320/636 [18:43<36:02,  6.84s/it] 52%|█████▏    | 328/636 [19:30<33:33,  6.54s/it] 53%|█████▎    | 336/636 [20:29<34:05,  6.82s/it] 54%|█████▍    | 344/636 [21:24<33:16,  6.84s/it] 55%|█████▌    | 352/636 [22:24<33:13,  7.02s/it] 57%|█████▋    | 360/636 [23:25<33:12,  7.22s/it] 58%|█████▊    | 368/636 [24:24<32:25,  7.26s/it] 59%|█████▉    | 376/636 [25:23<31:33,  7.28s/it] 60%|██████    | 384/636 [26:16<29:45,  7.09s/it] 62%|██████▏   | 392/636 [27:08<28:04,  6.90s/it] 63%|██████▎   | 400/636 [28:07<27:43,  7.05s/it] 64%|██████▍   | 408/636 [29:04<26:56,  7.09s/it] 65%|██████▌   | 416/636 [29:58<25:35,  6.98s/it] 67%|██████▋   | 424/636 [31:03<25:47,  7.30s/it] 68%|██████▊   | 432/636 [32:04<25:13,  7.42s/it] 69%|██████▉   | 440/636 [33:09<24:51,  7.61s/it] 70%|███████   | 448/636 [34:03<23:03,  7.36s/it] 72%|███████▏  | 456/636 [34:59<21:50,  7.28s/it] 73%|███████▎  | 464/636 [35:55<20:33,  7.17s/it] 74%|███████▍  | 472/636 [36:49<19:14,  7.04s/it] 75%|███████▌  | 480/636 [37:43<18:07,  6.97s/it] 77%|███████▋  | 488/636 [38:08<14:18,  5.80s/it] 78%|███████▊  | 496/636 [38:33<11:39,  4.99s/it] 79%|███████▉  | 504/636 [38:59<09:52,  4.49s/it] 81%|████████  | 512/636 [39:22<08:16,  4.00s/it] 82%|████████▏ | 520/636 [39:44<06:59,  3.62s/it] 83%|████████▎ | 528/636 [40:09<06:14,  3.47s/it] 84%|████████▍ | 536/636 [40:35<05:42,  3.42s/it] 86%|████████▌ | 544/636 [41:01<05:08,  3.36s/it] 87%|████████▋ | 552/636 [41:24<04:29,  3.21s/it] 88%|████████▊ | 560/636 [41:46<03:52,  3.06s/it] 89%|████████▉ | 568/636 [42:06<03:18,  2.92s/it] 91%|█████████ | 576/636 [42:28<02:52,  2.87s/it] 92%|█████████▏| 584/636 [42:48<02:23,  2.76s/it] 93%|█████████▎| 592/636 [43:11<02:01,  2.77s/it] 94%|█████████▍| 600/636 [43:33<01:39,  2.77s/it] 96%|█████████▌| 608/636 [43:53<01:15,  2.68s/it] 97%|█████████▋| 616/636 [44:14<00:53,  2.69s/it] 98%|█████████▊| 624/636 [44:39<00:33,  2.80s/it] 99%|█████████▉| 632/636 [44:59<00:10,  2.73s/it]100%|██████████| 636/636 [44:59<00:00,  4.25s/it]
  0%|          | 0/121 [00:00<?, ?it/s]  7%|▋         | 8/121 [00:22<05:19,  2.83s/it] 13%|█▎        | 16/121 [00:48<05:18,  3.04s/it] 20%|█▉        | 24/121 [01:10<04:46,  2.95s/it] 26%|██▋       | 32/121 [01:33<04:20,  2.93s/it] 33%|███▎      | 40/121 [01:58<04:01,  2.99s/it] 40%|███▉      | 48/121 [02:23<03:39,  3.00s/it] 46%|████▋     | 56/121 [02:44<03:08,  2.89s/it] 53%|█████▎    | 64/121 [03:08<02:46,  2.93s/it] 60%|█████▉    | 72/121 [03:34<02:27,  3.01s/it] 66%|██████▌   | 80/121 [03:59<02:05,  3.05s/it] 73%|███████▎  | 88/121 [04:25<01:42,  3.11s/it] 79%|███████▉  | 96/121 [04:48<01:16,  3.06s/it] 86%|████████▌ | 104/121 [05:12<00:51,  3.03s/it] 93%|█████████▎| 112/121 [05:35<00:27,  3.01s/it] 99%|█████████▉| 120/121 [06:00<00:03,  3.04s/it]100%|██████████| 121/121 [06:00<00:00,  2.98s/it]
  0%|          | 0/138 [00:00<?, ?it/s]  6%|▌         | 8/138 [00:18<05:05,  2.35s/it] 12%|█▏        | 16/138 [00:41<05:19,  2.62s/it] 17%|█▋        | 24/138 [01:01<04:53,  2.58s/it] 23%|██▎       | 32/138 [01:21<04:31,  2.56s/it] 29%|██▉       | 40/138 [01:43<04:15,  2.61s/it] 35%|███▍      | 48/138 [02:05<03:59,  2.66s/it] 41%|████      | 56/138 [02:28<03:42,  2.71s/it] 46%|████▋     | 64/138 [02:52<03:30,  2.84s/it] 52%|█████▏    | 72/138 [03:17<03:13,  2.93s/it] 58%|█████▊    | 80/138 [03:42<02:53,  2.99s/it] 64%|██████▍   | 88/138 [04:06<02:29,  3.00s/it] 70%|██████▉   | 96/138 [04:27<02:01,  2.88s/it] 75%|███████▌  | 104/138 [04:50<01:37,  2.87s/it] 81%|████████  | 112/138 [05:13<01:14,  2.87s/it] 87%|████████▋ | 120/138 [05:36<00:51,  2.88s/it] 93%|█████████▎| 128/138 [06:00<00:28,  2.89s/it] 99%|█████████▊| 136/138 [06:23<00:05,  2.88s/it]100%|██████████| 138/138 [06:23<00:00,  2.78s/it]2024-02-18 21:14:37 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='./output/AMI/stage_2/trainer_output/bin/', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='source', srcdict='dict.txt', target_lang='target', task='translation', tensorboard_logdir=None, testpref=None, tgtdict='dict.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='./output/AMI/stage_2/trainer_output/train.bpe', user_dir=None, validpref='./output/AMI/stage_2/trainer_output/val.bpe', workers=60)
2024-02-18 21:14:38 | INFO | fairseq_cli.preprocess | [source] Dictionary: 50264 types
2024-02-18 21:14:40 | INFO | fairseq_cli.preprocess | [source] ./output/AMI/stage_2/trainer_output/train.bpe.source: 97 sents, 151600 tokens, 0.0% replaced by <unk>
2024-02-18 21:14:40 | INFO | fairseq_cli.preprocess | [source] Dictionary: 50264 types
2024-02-18 21:14:42 | INFO | fairseq_cli.preprocess | [source] ./output/AMI/stage_2/trainer_output/val.bpe.source: 20 sents, 29487 tokens, 0.0% replaced by <unk>
2024-02-18 21:14:42 | INFO | fairseq_cli.preprocess | [target] Dictionary: 50264 types
2024-02-18 21:14:45 | INFO | fairseq_cli.preprocess | [target] ./output/AMI/stage_2/trainer_output/train.bpe.target: 97 sents, 30941 tokens, 0.0% replaced by <unk>
2024-02-18 21:14:45 | INFO | fairseq_cli.preprocess | [target] Dictionary: 50264 types
2024-02-18 21:14:47 | INFO | fairseq_cli.preprocess | [target] ./output/AMI/stage_2/trainer_output/val.bpe.target: 20 sents, 7464 tokens, 0.0% replaced by <unk>
2024-02-18 21:14:47 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to ./output/AMI/stage_2/trainer_output/bin/

CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.
To initialize your shell, run

    $ conda init <SHELL_NAME>

Currently supported shells are:
  - bash
  - fish
  - tcsh
  - xonsh
  - zsh
  - powershell

See 'conda init --help' for more information and options.

IMPORTANT: You may need to close and restart your shell after running 'conda init'.


2024-02-18 21:14:49 | INFO | fairseq_cli.train | Namespace(activation_fn='gelu', adam_betas='(0.9, 0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, all_gather_list_size=16384, arch='bart_large', attention_dropout=0.1, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.1, cpu=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='./output/AMI/stage_2/trainer_output/bin/', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_layerdrop=0, decoder_layers=12, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=False, decoder_output_dim=1024, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=12, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=False, end_learning_rate=0.0, eval_bleu=False, eval_bleu_args=None, eval_bleu_detok='space', eval_bleu_detok_args=None, eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=True, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, gen_subset='test', ignore_prefix_size=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, label_smoothing=0.1, layernorm_embedding=True, left_pad_source='True', left_pad_target='False', load_alignments=False, localsgd_frequency=3, log_format=None, log_interval=100, lr=[3e-05], lr_scheduler='polynomial_decay', max_epoch=0, max_source_positions=1024, max_target_positions=1024, max_tokens=2048, max_tokens_valid=2048, max_update=0, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1.0, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=2, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, relu_dropout=0.0, report_accuracy=False, required_batch_size_multiple=1, required_seq_len_multiple=1, reset_dataloader=True, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, restore_file='./bart.large.cnn/model.pt', save_dir='./output/AMI/stage_2/trainer_output/checkpoints', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=True, slowmo_algorithm='LocalSGD', slowmo_momentum=None, source_lang='source', stop_time_hours=0, target_lang='target', task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, total_num_update=30000, tpu=False, train_subset='train', truncate_source=True, update_freq=[4], upsample_primary=1, use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=500, weight_decay=0.01, zero_sharding='none')
2024-02-18 21:14:49 | INFO | fairseq.tasks.translation | [source] dictionary: 50264 types
2024-02-18 21:14:49 | INFO | fairseq.tasks.translation | [target] dictionary: 50264 types
2024-02-18 21:14:49 | INFO | fairseq.data.data_utils | loaded 20 examples from: ./output/AMI/stage_2/trainer_output/bin/valid.source-target.source
2024-02-18 21:14:49 | INFO | fairseq.data.data_utils | loaded 20 examples from: ./output/AMI/stage_2/trainer_output/bin/valid.source-target.target
2024-02-18 21:14:49 | INFO | fairseq.tasks.translation | ./output/AMI/stage_2/trainer_output/bin/ valid source-target 20 examples
2024-02-18 21:15:06 | INFO | fairseq_cli.train | BARTModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50264, 1024, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)
    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (6): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (7): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (8): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (9): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (10): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (11): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(50264, 1024, padding_idx=1)
    (embed_positions): LearnedPositionalEmbedding(1026, 1024, padding_idx=1)
    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (6): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (7): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (8): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (9): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (10): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
      (11): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=1024, out_features=50264, bias=False)
  )
  (classification_heads): ModuleDict()
)
2024-02-18 21:15:06 | INFO | fairseq_cli.train | task: translation (TranslationTask)
2024-02-18 21:15:06 | INFO | fairseq_cli.train | model: bart_large (BARTModel)
2024-02-18 21:15:06 | INFO | fairseq_cli.train | criterion: label_smoothed_cross_entropy (LabelSmoothedCrossEntropyCriterion)
2024-02-18 21:15:06 | INFO | fairseq_cli.train | num. model params: 406290432 (num. trained: 406290432)
2024-02-18 21:15:07 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2024-02-18 21:15:07 | INFO | fairseq.trainer | detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2024-02-18 21:15:07 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-02-18 21:15:07 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 23.870 GB ; name = Quadro P6000                            
2024-02-18 21:15:07 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-02-18 21:15:07 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2024-02-18 21:15:07 | INFO | fairseq_cli.train | max tokens per GPU = 2048 and max sentences per GPU = None
2024-02-18 21:15:09 | INFO | fairseq.trainer | loaded checkpoint ./bart.large.cnn/model.pt (epoch 5 @ 0 updates)
2024-02-18 21:15:09 | INFO | fairseq.trainer | NOTE: your device does NOT support faster training with --fp16, please switch to FP32 which is likely to be faster
2024-02-18 21:15:09 | INFO | fairseq.trainer | loading train data for epoch 1
2024-02-18 21:15:09 | INFO | fairseq.data.data_utils | loaded 97 examples from: ./output/AMI/stage_2/trainer_output/bin/train.source-target.source
2024-02-18 21:15:09 | INFO | fairseq.data.data_utils | loaded 97 examples from: ./output/AMI/stage_2/trainer_output/bin/train.source-target.target
2024-02-18 21:15:09 | INFO | fairseq.tasks.translation | ./output/AMI/stage_2/trainer_output/bin/ train source-target 97 examples
2024-02-18 21:15:09 | INFO | fairseq.trainer | begin training epoch 1
2024-02-18 21:15:13 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 64.0
2024-02-18 21:15:16 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 32.0
2024-02-18 21:15:19 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 16.0
2024-02-18 21:15:23 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 8.0
2024-02-18 21:15:26 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 4.0
2024-02-18 21:15:34 | INFO | fairseq.trainer | NOTE: overflow detected, setting loss scale to: 2.0
2024-02-18 21:15:44 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-18 21:15:47 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 6.839 | nll_loss 5.384 | ppl 41.76 | wps 3267.9 | wpb 746.4 | bsz 2 | num_updates 6
2024-02-18 21:15:47 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-18 21:15:59 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_2/trainer_output/checkpoints/checkpoint_best.pt (epoch 1 @ 6 updates, score 6.839) (writing took 12.59143566712737 seconds)
2024-02-18 21:15:59 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2024-02-18 21:15:59 | INFO | train | epoch 001 | loss 6.894 | nll_loss 5.472 | ppl 44.4 | wps 397.6 | ups 0.17 | wpb 2467.5 | bsz 7.7 | num_updates 6 | lr 3.6e-07 | gnorm 35.817 | clip 100 | loss_scale 2 | train_wall 35 | wall 52
2024-02-18 21:15:59 | INFO | fairseq.trainer | begin training epoch 2
2024-02-18 21:16:31 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-18 21:16:34 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 6.583 | nll_loss 5.09 | ppl 34.06 | wps 3210.1 | wpb 746.4 | bsz 2 | num_updates 18 | best_loss 6.583
2024-02-18 21:16:34 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-18 21:17:11 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_2/trainer_output/checkpoints/checkpoint_best.pt (epoch 2 @ 18 updates, score 6.583) (writing took 37.23611977137625 seconds)
2024-02-18 21:17:11 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2024-02-18 21:17:11 | INFO | train | epoch 002 | loss 6.742 | nll_loss 5.298 | ppl 39.34 | wps 432.2 | ups 0.17 | wpb 2578.4 | bsz 8.1 | num_updates 18 | lr 1.08e-06 | gnorm 26.876 | clip 100 | loss_scale 2 | train_wall 32 | wall 124
2024-02-18 21:17:11 | INFO | fairseq.trainer | begin training epoch 3
2024-02-18 21:17:43 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-18 21:17:45 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 6.275 | nll_loss 4.763 | ppl 27.14 | wps 3145.3 | wpb 746.4 | bsz 2 | num_updates 30 | best_loss 6.275
2024-02-18 21:17:45 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-18 21:18:22 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_2/trainer_output/checkpoints/checkpoint_best.pt (epoch 3 @ 30 updates, score 6.275) (writing took 36.5412460193038 seconds)
2024-02-18 21:18:22 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2024-02-18 21:18:22 | INFO | train | epoch 003 | loss 6.293 | nll_loss 4.791 | ppl 27.69 | wps 435.2 | ups 0.17 | wpb 2578.4 | bsz 8.1 | num_updates 30 | lr 1.8e-06 | gnorm 8.024 | clip 100 | loss_scale 2 | train_wall 32 | wall 195
2024-02-18 21:18:22 | INFO | fairseq.trainer | begin training epoch 4
2024-02-18 21:18:54 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-18 21:18:56 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 6.089 | nll_loss 4.573 | ppl 23.8 | wps 3200.1 | wpb 746.4 | bsz 2 | num_updates 42 | best_loss 6.089
2024-02-18 21:18:56 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-18 21:19:32 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_2/trainer_output/checkpoints/checkpoint_best.pt (epoch 4 @ 42 updates, score 6.089) (writing took 35.43908732198179 seconds)
2024-02-18 21:19:32 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2024-02-18 21:19:32 | INFO | train | epoch 004 | loss 5.95 | nll_loss 4.426 | ppl 21.49 | wps 442.5 | ups 0.17 | wpb 2578.4 | bsz 8.1 | num_updates 42 | lr 2.52e-06 | gnorm 4.375 | clip 100 | loss_scale 2 | train_wall 32 | wall 265
2024-02-18 21:19:32 | INFO | fairseq.trainer | begin training epoch 5
2024-02-18 21:20:04 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-18 21:20:06 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 5.995 | nll_loss 4.449 | ppl 21.85 | wps 3178.3 | wpb 746.4 | bsz 2 | num_updates 54 | best_loss 5.995
2024-02-18 21:20:06 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-18 21:20:40 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_2/trainer_output/checkpoints/checkpoint_best.pt (epoch 5 @ 54 updates, score 5.995) (writing took 33.246206594631076 seconds)
2024-02-18 21:20:40 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2024-02-18 21:20:40 | INFO | train | epoch 005 | loss 5.751 | nll_loss 4.204 | ppl 18.44 | wps 457.1 | ups 0.18 | wpb 2578.4 | bsz 8.1 | num_updates 54 | lr 3.24e-06 | gnorm 3.39 | clip 100 | loss_scale 2 | train_wall 32 | wall 332
2024-02-18 21:20:40 | INFO | fairseq.trainer | begin training epoch 6
2024-02-18 21:21:12 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-18 21:21:14 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 5.925 | nll_loss 4.357 | ppl 20.49 | wps 3206 | wpb 746.4 | bsz 2 | num_updates 66 | best_loss 5.925
2024-02-18 21:21:14 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-18 21:21:47 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_2/trainer_output/checkpoints/checkpoint_best.pt (epoch 6 @ 66 updates, score 5.925) (writing took 33.47304000891745 seconds)
2024-02-18 21:21:47 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2024-02-18 21:21:47 | INFO | train | epoch 006 | loss 5.582 | nll_loss 4.001 | ppl 16.01 | wps 455.7 | ups 0.18 | wpb 2578.4 | bsz 8.1 | num_updates 66 | lr 3.96e-06 | gnorm 2.934 | clip 100 | loss_scale 2 | train_wall 32 | wall 400
2024-02-18 21:21:47 | INFO | fairseq.trainer | begin training epoch 7
2024-02-18 21:22:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-18 21:22:22 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 5.859 | nll_loss 4.283 | ppl 19.47 | wps 3193.3 | wpb 746.4 | bsz 2 | num_updates 78 | best_loss 5.859
2024-02-18 21:22:22 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-18 21:22:57 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_2/trainer_output/checkpoints/checkpoint_best.pt (epoch 7 @ 78 updates, score 5.859) (writing took 35.32249930873513 seconds)
2024-02-18 21:22:57 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2024-02-18 21:22:57 | INFO | train | epoch 007 | loss 5.441 | nll_loss 3.833 | ppl 14.25 | wps 443.1 | ups 0.17 | wpb 2578.4 | bsz 8.1 | num_updates 78 | lr 4.68e-06 | gnorm 2.696 | clip 100 | loss_scale 2 | train_wall 32 | wall 470
2024-02-18 21:22:57 | INFO | fairseq.trainer | begin training epoch 8
2024-02-18 21:23:29 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-18 21:23:32 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 5.809 | nll_loss 4.228 | ppl 18.74 | wps 3217.6 | wpb 746.4 | bsz 2 | num_updates 90 | best_loss 5.809
2024-02-18 21:23:32 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-18 21:24:06 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_2/trainer_output/checkpoints/checkpoint_best.pt (epoch 8 @ 90 updates, score 5.809) (writing took 33.834931407123804 seconds)
2024-02-18 21:24:06 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2024-02-18 21:24:06 | INFO | train | epoch 008 | loss 5.329 | nll_loss 3.708 | ppl 13.06 | wps 453 | ups 0.18 | wpb 2578.4 | bsz 8.1 | num_updates 90 | lr 5.4e-06 | gnorm 2.644 | clip 100 | loss_scale 2 | train_wall 32 | wall 538
2024-02-18 21:24:06 | INFO | fairseq.trainer | begin training epoch 9
2024-02-18 21:24:33 | INFO | train_inner | epoch 009:     10 / 12 loss=5.864, nll_loss=4.315, ppl=19.91, wps=468.8, ups=0.18, wpb=2576.2, bsz=8.1, num_updates=100, lr=6e-06, gnorm=8.517, clip=100, loss_scale=2, train_wall=268, wall=565
2024-02-18 21:24:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-18 21:24:40 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 5.778 | nll_loss 4.185 | ppl 18.19 | wps 3203 | wpb 746.4 | bsz 2 | num_updates 102 | best_loss 5.778
2024-02-18 21:24:40 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-18 21:25:13 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_2/trainer_output/checkpoints/checkpoint_best.pt (epoch 9 @ 102 updates, score 5.778) (writing took 32.72105675935745 seconds)
2024-02-18 21:25:13 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2024-02-18 21:25:13 | INFO | train | epoch 009 | loss 5.207 | nll_loss 3.566 | ppl 11.84 | wps 460.3 | ups 0.18 | wpb 2578.4 | bsz 8.1 | num_updates 102 | lr 6.12e-06 | gnorm 2.556 | clip 100 | loss_scale 2 | train_wall 32 | wall 606
2024-02-18 21:25:13 | INFO | fairseq.trainer | begin training epoch 10
2024-02-18 21:25:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-18 21:25:47 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 5.739 | nll_loss 4.142 | ppl 17.66 | wps 3250.4 | wpb 746.4 | bsz 2 | num_updates 114 | best_loss 5.739
2024-02-18 21:25:47 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-18 21:26:24 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_2/trainer_output/checkpoints/checkpoint_best.pt (epoch 10 @ 114 updates, score 5.739) (writing took 36.90692789852619 seconds)
2024-02-18 21:26:24 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2024-02-18 21:26:24 | INFO | train | epoch 010 | loss 5.096 | nll_loss 3.439 | ppl 10.85 | wps 433.5 | ups 0.17 | wpb 2578.4 | bsz 8.1 | num_updates 114 | lr 6.84e-06 | gnorm 2.508 | clip 100 | loss_scale 2 | train_wall 32 | wall 677
2024-02-18 21:26:24 | INFO | fairseq.trainer | begin training epoch 11
2024-02-18 21:26:56 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-18 21:26:59 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 5.712 | nll_loss 4.103 | ppl 17.18 | wps 3214.8 | wpb 746.4 | bsz 2 | num_updates 126 | best_loss 5.712
2024-02-18 21:26:59 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-18 21:27:36 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_2/trainer_output/checkpoints/checkpoint_best.pt (epoch 11 @ 126 updates, score 5.712) (writing took 37.10107935220003 seconds)
2024-02-18 21:27:36 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2024-02-18 21:27:36 | INFO | train | epoch 011 | loss 4.987 | nll_loss 3.311 | ppl 9.92 | wps 431.8 | ups 0.17 | wpb 2578.4 | bsz 8.1 | num_updates 126 | lr 7.56e-06 | gnorm 2.524 | clip 100 | loss_scale 2 | train_wall 32 | wall 749
2024-02-18 21:27:36 | INFO | fairseq.trainer | begin training epoch 12
2024-02-18 21:28:08 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-18 21:28:10 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 5.7 | nll_loss 4.091 | ppl 17.04 | wps 3182.7 | wpb 746.4 | bsz 2 | num_updates 138 | best_loss 5.7
2024-02-18 21:28:10 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-18 21:28:47 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_2/trainer_output/checkpoints/checkpoint_best.pt (epoch 12 @ 138 updates, score 5.7) (writing took 36.81261949241161 seconds)
2024-02-18 21:28:47 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2024-02-18 21:28:47 | INFO | train | epoch 012 | loss 4.867 | nll_loss 3.176 | ppl 9.04 | wps 434 | ups 0.17 | wpb 2578.4 | bsz 8.1 | num_updates 138 | lr 8.28e-06 | gnorm 2.507 | clip 100 | loss_scale 2 | train_wall 32 | wall 820
2024-02-18 21:28:47 | INFO | fairseq.trainer | begin training epoch 13
2024-02-18 21:29:19 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-18 21:29:22 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 5.689 | nll_loss 4.069 | ppl 16.78 | wps 3201.2 | wpb 746.4 | bsz 2 | num_updates 150 | best_loss 5.689
2024-02-18 21:29:22 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-18 21:29:58 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_2/trainer_output/checkpoints/checkpoint_best.pt (epoch 13 @ 150 updates, score 5.689) (writing took 36.73577347956598 seconds)
2024-02-18 21:29:58 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2024-02-18 21:29:58 | INFO | train | epoch 013 | loss 4.765 | nll_loss 3.057 | ppl 8.32 | wps 434.9 | ups 0.17 | wpb 2578.4 | bsz 8.1 | num_updates 150 | lr 9e-06 | gnorm 2.521 | clip 100 | loss_scale 2 | train_wall 32 | wall 891
2024-02-18 21:29:58 | INFO | fairseq.trainer | begin training epoch 14
2024-02-18 21:30:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-18 21:30:33 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 5.687 | nll_loss 4.071 | ppl 16.81 | wps 3221.5 | wpb 746.4 | bsz 2 | num_updates 162 | best_loss 5.687
2024-02-18 21:30:33 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-18 21:31:06 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_2/trainer_output/checkpoints/checkpoint_best.pt (epoch 14 @ 162 updates, score 5.687) (writing took 33.58578886277974 seconds)
2024-02-18 21:31:06 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2024-02-18 21:31:06 | INFO | train | epoch 014 | loss 4.654 | nll_loss 2.931 | ppl 7.63 | wps 455 | ups 0.18 | wpb 2578.4 | bsz 8.1 | num_updates 162 | lr 9.72e-06 | gnorm 2.506 | clip 100 | loss_scale 2 | train_wall 32 | wall 959
2024-02-18 21:31:06 | INFO | fairseq.trainer | begin training epoch 15
2024-02-18 21:31:38 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-18 21:31:41 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 5.678 | nll_loss 4.05 | ppl 16.57 | wps 3224.1 | wpb 746.4 | bsz 2 | num_updates 174 | best_loss 5.678
2024-02-18 21:31:41 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-18 21:32:15 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_2/trainer_output/checkpoints/checkpoint_best.pt (epoch 15 @ 174 updates, score 5.678) (writing took 33.818518145009875 seconds)
2024-02-18 21:32:15 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2024-02-18 21:32:15 | INFO | train | epoch 015 | loss 4.541 | nll_loss 2.797 | ppl 6.95 | wps 453 | ups 0.18 | wpb 2578.4 | bsz 8.1 | num_updates 174 | lr 1.044e-05 | gnorm 2.518 | clip 100 | loss_scale 2 | train_wall 32 | wall 1027
2024-02-18 21:32:15 | INFO | fairseq.trainer | begin training epoch 16
2024-02-18 21:32:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-18 21:32:49 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 5.678 | nll_loss 4.044 | ppl 16.5 | wps 3242.6 | wpb 746.4 | bsz 2 | num_updates 186 | best_loss 5.678
2024-02-18 21:32:49 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-18 21:33:21 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_2/trainer_output/checkpoints/checkpoint_best.pt (epoch 16 @ 186 updates, score 5.678) (writing took 32.04629767499864 seconds)
2024-02-18 21:33:21 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2024-02-18 21:33:21 | INFO | train | epoch 016 | loss 4.453 | nll_loss 2.698 | ppl 6.49 | wps 466 | ups 0.18 | wpb 2578.4 | bsz 8.1 | num_updates 186 | lr 1.116e-05 | gnorm 2.576 | clip 100 | loss_scale 2 | train_wall 32 | wall 1094
2024-02-18 21:33:21 | INFO | fairseq.trainer | begin training epoch 17
2024-02-18 21:33:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2024-02-18 21:33:55 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 5.681 | nll_loss 4.04 | ppl 16.45 | wps 3158.5 | wpb 746.4 | bsz 2 | num_updates 198 | best_loss 5.678
2024-02-18 21:33:55 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 2 runs
2024-02-18 21:33:55 | INFO | fairseq_cli.train | begin save checkpoint
2024-02-18 21:34:12 | INFO | fairseq.checkpoint_utils | saved checkpoint ./output/AMI/stage_2/trainer_output/checkpoints/checkpoint_last.pt (epoch 17 @ 198 updates, score 5.681) (writing took 17.081937761977315 seconds)
2024-02-18 21:34:12 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2024-02-18 21:34:12 | INFO | train | epoch 017 | loss 4.338 | nll_loss 2.565 | ppl 5.92 | wps 601.6 | ups 0.23 | wpb 2578.4 | bsz 8.1 | num_updates 198 | lr 1.188e-05 | gnorm 2.566 | clip 100 | loss_scale 2 | train_wall 32 | wall 1145
2024-02-18 21:34:12 | INFO | fairseq_cli.train | done training in 1143.1 seconds

2024-02-18 21:34:13 | INFO | fairseq.file_utils | loading archive file ./output/AMI/stage_2/trainer_output
2024-02-18 21:34:15 | INFO | fairseq.tasks.translation | [source] dictionary: 50264 types
2024-02-18 21:34:15 | INFO | fairseq.tasks.translation | [target] dictionary: 50264 types
  0%|          | 0/19 [00:00<?, ?it/s] 42%|████▏     | 8/19 [02:42<03:43, 20.32s/it] 84%|████████▍ | 16/19 [04:46<00:52, 17.49s/it]100%|██████████| 19/19 [04:46<00:00, 15.09s/it]
Finish loading stage 1 dataset!
Train size: 637
Val size: 122
Test size: 139
Finish loading stage 1 dataset!
Finish loading stage 2 dataset!
Train size: 97
Val size: 20
Test size: 20
Traceback (most recent call last):
  File "run.py", line 135, in <module>
    rouge_scores = rouge(cur_target['test'], cur_hypo['test'], rouge_folder)
  File "/home/is/kaifan-l/private_room/proj-repos/Summ-N/utils/AnyROUGE.py", line 31, in rouge
    r = pyrouge.Rouge155()
  File "/home/is/kaifan-l/miniconda3/envs/SummN/lib/python3.7/site-packages/pyrouge/Rouge155.py", line 88, in __init__
    self.__set_rouge_dir(rouge_dir)
  File "/home/is/kaifan-l/miniconda3/envs/SummN/lib/python3.7/site-packages/pyrouge/Rouge155.py", line 407, in __set_rouge_dir
    self.data_dir = os.path.join(self._home_dir, 'data')
  File "/home/is/kaifan-l/miniconda3/envs/SummN/lib/python3.7/site-packages/pyrouge/Rouge155.py", line 543, in fset
    verify_dir(path, dir_name)
  File "/home/is/kaifan-l/miniconda3/envs/SummN/lib/python3.7/site-packages/pyrouge/utils/file_utils.py", line 87, in verify_dir
    raise Exception(msg)
Exception: Cannot set data directory because the path /home/is/kaifan-l/private_room/proj-repos/Summ-N/AnyROUGE/ThirdParty/ROUGE/ROUGE-1.5.5/data does not exist.
